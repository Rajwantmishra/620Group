{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works of Edgar Allan Poe - Volume 1\n",
    "Project Gutenberg\n",
    "https://www.gutenberg.org/files/2147/2147-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from urllib.request import urlopen\n",
    "import nltk\n",
    "import re\n",
    "import pprint\n",
    "from nltk.corpus import stopwords as sw\n",
    "import matplotlib.pyplot as plot\n",
    "import pandas as pd\n",
    "import string\n",
    "pd.set_option('display.max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/2147/2147-0.txt\"\n",
    "raw=''\n",
    "with urlopen(url) as response:\n",
    "     for line in response:\n",
    "         line = line.decode('utf-8')  # Decoding the binary data to text.\n",
    "         raw = raw + line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "550334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ufeffProject Gutenbergâ€™s The Works of Edgar Allan Poe, by Edgar Allan Poe\\r\\n\\r\\nThis eBook is for the use of anyone anywhere at no cost and with\\r\\nalmost no restrictions whatsoever.  You may copy it, give it away or\\r\\nre-use it under the terms of the Project Gutenberg License included\\r\\nwith this eBook or online at www.gutenberg.org\\r\\n\\r\\n\\r\\nTitle: The Works of Edgar Allan Poe\\r\\n       Volume 1 (of 5) of the Raven Edition\\r\\n\\r\\nAuthor: Edgar Allan Poe\\r\\n\\r\\nRelease Date: May 19, 2008 [EBook #2147]\\r\\nLast Updated: Oct'"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(raw))\n",
    "print(len(raw))\n",
    "# Print the raw data\n",
    "raw[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 550,334 characters.  This includes spaces, characters to indicate new lines and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is a long introduction about Edgar Allan Poe before the story begins.  \n",
    "#The string will be sliced so that it only includes Poe's writing.\n",
    "raw.find(\"THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL\")\n",
    "raw.rfind(\"END\")\n",
    "raw = raw[51526:531158]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "traw= 'THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)\\r\\n\\r\\nBY late accounts from Rotterdam, that city seems to be in a high state\\r\\nof philosophical excitement. Indeed, phenomena have there occurred of\\r\\na nature so completely unexpected--so entirely novel--so utterly at\\r\\nvariance with preconceived opinions--as to leave no doubt on my mind\\r\\nthat long ere this all Europe is in an uproar, all physics in a ferment,\\r\\nall reason and astronomy together by the ears.\\r\\n\\r\\nIt appears that on the---- day of---- (I am not positive about the\\r\\ndate), a vast crowd of people, for purposes not specifically\\r\\nmentioned, were assembled in the great square of the Exchange in the\\r\\nwell-conditioned city of Rotterdam. The day was warm--unusually so for\\r\\nthe season--there was hardly a breath of air stirring; and the multitude\\r\\nwere in no bad humor at being now and then besprinkled with friendly\\r\\nshowers of momentary duration, that fell from large white masses\\r\\nof cloud which chequered in a fitful manner the blue vault of the\\r\\nfirmament. Nevertheless, about noon, a slight but remarkable agitation\\r\\nbecame apparent in the assembly: the clattering of ten thousand tongues\\r\\nsucceeded; and, in an instant afterward, ten thousand faces were\\r\\nupturned toward the heavens, ten thousand pipes descended simultaneously\\r\\nfrom the corners of ten thousand mouths, and a shout, which could be\\r\\ncompared to nothing but the roaring of Niagara, resounded long, loudly,\\r\\nand furiously, through all the environs of Rotterdam.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00-46: THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alternate ways to find start and end of Book text \n",
    "for m in re.finditer(r\"THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL|END\", raw):\n",
    "    print ('%02d-%02d: %s' % (m.start(), m.end(), m.group(0)))\n",
    "\n",
    "raw.find(\"THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL\")\n",
    "raw.rfind(\"END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw =traw \n",
    "parsedData = raw.replace('\\r\\n', '\\n').split('\\n')\n",
    "parsedData[0:5]\n",
    "fullCorpus = pd.DataFrame({\n",
    "      'book_data': parsedData[:]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullCorpus = fullCorpus[fullCorpus['book_data']!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7107\n",
      "Total Book has 7107 rows\n"
     ]
    }
   ],
   "source": [
    "print(len(fullCorpus.book_data))\n",
    "# How many Rows are there?\n",
    "\n",
    "print(\"Total Book has {} rows\".format(len(fullCorpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing text data\n",
    "Cleaning (or pre-processing) the data typically consists of a number of steps:\n",
    "\n",
    "+ Remove punctuation\n",
    "+ Tokenization\n",
    "+ Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BY late accounts from Rotterdam, that city seems to be in a high state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of philosophical excitement. Indeed, phenomena have there occurred of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a nature so completely unexpected--so entirely novel--so utterly at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>variance with preconceived opinions--as to leave no doubt on my mind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                book_data\n",
       "0                     THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)\n",
       "2  BY late accounts from Rotterdam, that city seems to be in a high state\n",
       "3   of philosophical excitement. Indeed, phenomena have there occurred of\n",
       "4     a nature so completely unexpected--so entirely novel--so utterly at\n",
       "5    variance with preconceived opinions--as to leave no doubt on my mind"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullCorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_data</th>\n",
       "      <th>book_data_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)</td>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BY late accounts from Rotterdam, that city seems to be in a high state</td>\n",
       "      <td>BY late accounts from Rotterdam that city seems to be in a high state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of philosophical excitement. Indeed, phenomena have there occurred of</td>\n",
       "      <td>of philosophical excitement Indeed phenomena have there occurred of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a nature so completely unexpected--so entirely novel--so utterly at</td>\n",
       "      <td>a nature so completely unexpectedso entirely novelso utterly at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>variance with preconceived opinions--as to leave no doubt on my mind</td>\n",
       "      <td>variance with preconceived opinionsas to leave no doubt on my mind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                book_data  \\\n",
       "0                     THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)   \n",
       "2  BY late accounts from Rotterdam, that city seems to be in a high state   \n",
       "3   of philosophical excitement. Indeed, phenomena have there occurred of   \n",
       "4     a nature so completely unexpected--so entirely novel--so utterly at   \n",
       "5    variance with preconceived opinions--as to leave no doubt on my mind   \n",
       "\n",
       "                                                         book_data_clean  \n",
       "0                       THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1  \n",
       "2  BY late accounts from Rotterdam that city seems to be in a high state  \n",
       "3    of philosophical excitement Indeed phenomena have there occurred of  \n",
       "4        a nature so completely unexpectedso entirely novelso utterly at  \n",
       "5     variance with preconceived opinionsas to leave no doubt on my mind  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "\n",
    "fullCorpus['book_data_clean'] = fullCorpus['book_data'].apply(lambda x: remove_punct(x))\n",
    "\n",
    "fullCorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_data</th>\n",
       "      <th>book_data_clean</th>\n",
       "      <th>book_data_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)</td>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1</td>\n",
       "      <td>[THE, UNPARALLELED, ADVENTURES, OF, ONE, HANS, PFAALL, 1, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BY late accounts from Rotterdam, that city seems to be in a high state</td>\n",
       "      <td>BY late accounts from Rotterdam that city seems to be in a high state</td>\n",
       "      <td>[BY, late, accounts, from, Rotterdam, that, city, seems, to, be, in, a, high, state]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of philosophical excitement. Indeed, phenomena have there occurred of</td>\n",
       "      <td>of philosophical excitement Indeed phenomena have there occurred of</td>\n",
       "      <td>[of, philosophical, excitement, Indeed, phenomena, have, there, occurred, of]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a nature so completely unexpected--so entirely novel--so utterly at</td>\n",
       "      <td>a nature so completely unexpectedso entirely novelso utterly at</td>\n",
       "      <td>[a, nature, so, completely, unexpected, so, entirely, novel, so, utterly, at]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>variance with preconceived opinions--as to leave no doubt on my mind</td>\n",
       "      <td>variance with preconceived opinionsas to leave no doubt on my mind</td>\n",
       "      <td>[variance, with, preconceived, opinions, as, to, leave, no, doubt, on, my, mind]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                book_data  \\\n",
       "0                     THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)   \n",
       "2  BY late accounts from Rotterdam, that city seems to be in a high state   \n",
       "3   of philosophical excitement. Indeed, phenomena have there occurred of   \n",
       "4     a nature so completely unexpected--so entirely novel--so utterly at   \n",
       "5    variance with preconceived opinions--as to leave no doubt on my mind   \n",
       "\n",
       "                                                         book_data_clean  \\\n",
       "0                       THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1   \n",
       "2  BY late accounts from Rotterdam that city seems to be in a high state   \n",
       "3    of philosophical excitement Indeed phenomena have there occurred of   \n",
       "4        a nature so completely unexpectedso entirely novelso utterly at   \n",
       "5     variance with preconceived opinionsas to leave no doubt on my mind   \n",
       "\n",
       "                                                                    book_data_tokenized  \n",
       "0                           [THE, UNPARALLELED, ADVENTURES, OF, ONE, HANS, PFAALL, 1, ]  \n",
       "2  [BY, late, accounts, from, Rotterdam, that, city, seems, to, be, in, a, high, state]  \n",
       "3         [of, philosophical, excitement, Indeed, phenomena, have, there, occurred, of]  \n",
       "4         [a, nature, so, completely, unexpected, so, entirely, novel, so, utterly, at]  \n",
       "5      [variance, with, preconceived, opinions, as, to, leave, no, doubt, on, my, mind]  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "fullCorpus['book_data_tokenized'] = fullCorpus['book_data'].apply(lambda x: tokenize(x))\n",
    "\n",
    "fullCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_data</th>\n",
       "      <th>book_data_clean</th>\n",
       "      <th>book_data_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)</td>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1</td>\n",
       "      <td>[the, unparalleled, adventures, of, one, hans, pfaall, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BY late accounts from Rotterdam, that city seems to be in a high state</td>\n",
       "      <td>BY late accounts from Rotterdam that city seems to be in a high state</td>\n",
       "      <td>[by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of philosophical excitement. Indeed, phenomena have there occurred of</td>\n",
       "      <td>of philosophical excitement Indeed phenomena have there occurred of</td>\n",
       "      <td>[of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a nature so completely unexpected--so entirely novel--so utterly at</td>\n",
       "      <td>a nature so completely unexpectedso entirely novelso utterly at</td>\n",
       "      <td>[a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>variance with preconceived opinions--as to leave no doubt on my mind</td>\n",
       "      <td>variance with preconceived opinionsas to leave no doubt on my mind</td>\n",
       "      <td>[variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                book_data  \\\n",
       "0                     THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)   \n",
       "2  BY late accounts from Rotterdam, that city seems to be in a high state   \n",
       "3   of philosophical excitement. Indeed, phenomena have there occurred of   \n",
       "4     a nature so completely unexpected--so entirely novel--so utterly at   \n",
       "5    variance with preconceived opinions--as to leave no doubt on my mind   \n",
       "\n",
       "                                                         book_data_clean  \\\n",
       "0                       THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1   \n",
       "2  BY late accounts from Rotterdam that city seems to be in a high state   \n",
       "3    of philosophical excitement Indeed phenomena have there occurred of   \n",
       "4        a nature so completely unexpectedso entirely novelso utterly at   \n",
       "5     variance with preconceived opinionsas to leave no doubt on my mind   \n",
       "\n",
       "                                                                    book_data_tokenized  \n",
       "0                             [the, unparalleled, adventures, of, one, hans, pfaall, 1]  \n",
       "2  [by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]  \n",
       "3         [of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]  \n",
       "4             [a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]  \n",
       "5        [variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullCorpus['book_data_tokenized'] = fullCorpus['book_data_clean'].apply(lambda x: tokenize(x.lower()))\n",
    "\n",
    "fullCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_data</th>\n",
       "      <th>book_data_clean</th>\n",
       "      <th>book_data_tokenized</th>\n",
       "      <th>book_data_tokenized_nlkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)</td>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1</td>\n",
       "      <td>[the, unparalleled, adventures, of, one, hans, pfaall, 1]</td>\n",
       "      <td>[the, unparalleled, adventures, of, one, hans, pfaall, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BY late accounts from Rotterdam, that city seems to be in a high state</td>\n",
       "      <td>BY late accounts from Rotterdam that city seems to be in a high state</td>\n",
       "      <td>[by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]</td>\n",
       "      <td>[by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of philosophical excitement. Indeed, phenomena have there occurred of</td>\n",
       "      <td>of philosophical excitement Indeed phenomena have there occurred of</td>\n",
       "      <td>[of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]</td>\n",
       "      <td>[of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a nature so completely unexpected--so entirely novel--so utterly at</td>\n",
       "      <td>a nature so completely unexpectedso entirely novelso utterly at</td>\n",
       "      <td>[a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]</td>\n",
       "      <td>[a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>variance with preconceived opinions--as to leave no doubt on my mind</td>\n",
       "      <td>variance with preconceived opinionsas to leave no doubt on my mind</td>\n",
       "      <td>[variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]</td>\n",
       "      <td>[variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>that long ere this all Europe is in an uproar, all physics in a ferment,</td>\n",
       "      <td>that long ere this all Europe is in an uproar all physics in a ferment</td>\n",
       "      <td>[that, long, ere, this, all, europe, is, in, an, uproar, all, physics, in, a, ferment]</td>\n",
       "      <td>[that, long, ere, this, all, europe, is, in, an, uproar, all, physics, in, a, ferment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>all reason and astronomy together by the ears.</td>\n",
       "      <td>all reason and astronomy together by the ears</td>\n",
       "      <td>[all, reason, and, astronomy, together, by, the, ears]</td>\n",
       "      <td>[all, reason, and, astronomy, together, by, the, ears]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It appears that on the---- day of---- (I am not positive about the</td>\n",
       "      <td>It appears that on the day of I am not positive about the</td>\n",
       "      <td>[it, appears, that, on, the, day, of, i, am, not, positive, about, the]</td>\n",
       "      <td>[it, appears, that, on, the, day, of, i, am, not, positive, about, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>date), a vast crowd of people, for purposes not specifically</td>\n",
       "      <td>date a vast crowd of people for purposes not specifically</td>\n",
       "      <td>[date, a, vast, crowd, of, people, for, purposes, not, specifically]</td>\n",
       "      <td>[date, a, vast, crowd, of, people, for, purposes, not, specifically]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mentioned, were assembled in the great square of the Exchange in the</td>\n",
       "      <td>mentioned were assembled in the great square of the Exchange in the</td>\n",
       "      <td>[mentioned, were, assembled, in, the, great, square, of, the, exchange, in, the]</td>\n",
       "      <td>[mentioned, were, assembled, in, the, great, square, of, the, exchange, in, the]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   book_data  \\\n",
       "0                        THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)   \n",
       "2     BY late accounts from Rotterdam, that city seems to be in a high state   \n",
       "3      of philosophical excitement. Indeed, phenomena have there occurred of   \n",
       "4        a nature so completely unexpected--so entirely novel--so utterly at   \n",
       "5       variance with preconceived opinions--as to leave no doubt on my mind   \n",
       "6   that long ere this all Europe is in an uproar, all physics in a ferment,   \n",
       "7                             all reason and astronomy together by the ears.   \n",
       "9         It appears that on the---- day of---- (I am not positive about the   \n",
       "10              date), a vast crowd of people, for purposes not specifically   \n",
       "11      mentioned, were assembled in the great square of the Exchange in the   \n",
       "\n",
       "                                                           book_data_clean  \\\n",
       "0                         THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1   \n",
       "2    BY late accounts from Rotterdam that city seems to be in a high state   \n",
       "3      of philosophical excitement Indeed phenomena have there occurred of   \n",
       "4          a nature so completely unexpectedso entirely novelso utterly at   \n",
       "5       variance with preconceived opinionsas to leave no doubt on my mind   \n",
       "6   that long ere this all Europe is in an uproar all physics in a ferment   \n",
       "7                            all reason and astronomy together by the ears   \n",
       "9                It appears that on the day of I am not positive about the   \n",
       "10               date a vast crowd of people for purposes not specifically   \n",
       "11     mentioned were assembled in the great square of the Exchange in the   \n",
       "\n",
       "                                                                       book_data_tokenized  \\\n",
       "0                                [the, unparalleled, adventures, of, one, hans, pfaall, 1]   \n",
       "2     [by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]   \n",
       "3            [of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]   \n",
       "4                [a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]   \n",
       "5           [variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]   \n",
       "6   [that, long, ere, this, all, europe, is, in, an, uproar, all, physics, in, a, ferment]   \n",
       "7                                   [all, reason, and, astronomy, together, by, the, ears]   \n",
       "9                  [it, appears, that, on, the, day, of, i, am, not, positive, about, the]   \n",
       "10                    [date, a, vast, crowd, of, people, for, purposes, not, specifically]   \n",
       "11        [mentioned, were, assembled, in, the, great, square, of, the, exchange, in, the]   \n",
       "\n",
       "                                                                  book_data_tokenized_nlkt  \n",
       "0                                [the, unparalleled, adventures, of, one, hans, pfaall, 1]  \n",
       "2     [by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]  \n",
       "3            [of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]  \n",
       "4                [a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]  \n",
       "5           [variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]  \n",
       "6   [that, long, ere, this, all, europe, is, in, an, uproar, all, physics, in, a, ferment]  \n",
       "7                                   [all, reason, and, astronomy, together, by, the, ears]  \n",
       "9                  [it, appears, that, on, the, day, of, i, am, not, positive, about, the]  \n",
       "10                    [date, a, vast, crowd, of, people, for, purposes, not, specifically]  \n",
       "11        [mentioned, were, assembled, in, the, great, square, of, the, exchange, in, the]  "
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullCorpus['book_data_tokenized_nlkt'] = fullCorpus['book_data_clean'].apply(lambda x: nltk.word_tokenize(x.lower()))\n",
    "\n",
    "fullCorpus.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "stopword.append('upon')\n",
    "stopword.append('would')\n",
    "stopword.append('us')\n",
    "stopword.append('would')\n",
    "stopword.append('could')\n",
    "stopword.append('much')\n",
    "stopword.append('great')\n",
    "stopword[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_data</th>\n",
       "      <th>book_data_clean</th>\n",
       "      <th>book_data_tokenized</th>\n",
       "      <th>book_data_tokenized_nlkt</th>\n",
       "      <th>book_data_nostop</th>\n",
       "      <th>book_data_stemmed</th>\n",
       "      <th>book_data_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)</td>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1</td>\n",
       "      <td>[the, unparalleled, adventures, of, one, hans, pfaall, 1]</td>\n",
       "      <td>[the, unparalleled, adventures, of, one, hans, pfaall, 1]</td>\n",
       "      <td>[unparalleled, adventures, one, hans, pfaall, 1]</td>\n",
       "      <td>[unparallel, adventur, one, han, pfaall, 1]</td>\n",
       "      <td>[unparalleled, adventure, one, han, pfaall, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BY late accounts from Rotterdam, that city seems to be in a high state</td>\n",
       "      <td>BY late accounts from Rotterdam that city seems to be in a high state</td>\n",
       "      <td>[by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]</td>\n",
       "      <td>[by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]</td>\n",
       "      <td>[late, accounts, rotterdam, city, seems, high, state]</td>\n",
       "      <td>[late, account, rotterdam, citi, seem, high, state]</td>\n",
       "      <td>[late, account, rotterdam, city, seems, high, state]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of philosophical excitement. Indeed, phenomena have there occurred of</td>\n",
       "      <td>of philosophical excitement Indeed phenomena have there occurred of</td>\n",
       "      <td>[of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]</td>\n",
       "      <td>[of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]</td>\n",
       "      <td>[philosophical, excitement, indeed, phenomena, occurred]</td>\n",
       "      <td>[philosoph, excit, inde, phenomena, occur]</td>\n",
       "      <td>[philosophical, excitement, indeed, phenomenon, occurred]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a nature so completely unexpected--so entirely novel--so utterly at</td>\n",
       "      <td>a nature so completely unexpectedso entirely novelso utterly at</td>\n",
       "      <td>[a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]</td>\n",
       "      <td>[a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]</td>\n",
       "      <td>[nature, completely, unexpectedso, entirely, novelso, utterly]</td>\n",
       "      <td>[natur, complet, unexpectedso, entir, novelso, utterli]</td>\n",
       "      <td>[nature, completely, unexpectedso, entirely, novelso, utterly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>variance with preconceived opinions--as to leave no doubt on my mind</td>\n",
       "      <td>variance with preconceived opinionsas to leave no doubt on my mind</td>\n",
       "      <td>[variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]</td>\n",
       "      <td>[variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]</td>\n",
       "      <td>[variance, preconceived, opinionsas, leave, doubt, mind]</td>\n",
       "      <td>[varianc, preconceiv, opinionsa, leav, doubt, mind]</td>\n",
       "      <td>[variance, preconceived, opinionsas, leave, doubt, mind]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                book_data  \\\n",
       "0                     THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)   \n",
       "2  BY late accounts from Rotterdam, that city seems to be in a high state   \n",
       "3   of philosophical excitement. Indeed, phenomena have there occurred of   \n",
       "4     a nature so completely unexpected--so entirely novel--so utterly at   \n",
       "5    variance with preconceived opinions--as to leave no doubt on my mind   \n",
       "\n",
       "                                                         book_data_clean  \\\n",
       "0                       THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1   \n",
       "2  BY late accounts from Rotterdam that city seems to be in a high state   \n",
       "3    of philosophical excitement Indeed phenomena have there occurred of   \n",
       "4        a nature so completely unexpectedso entirely novelso utterly at   \n",
       "5     variance with preconceived opinionsas to leave no doubt on my mind   \n",
       "\n",
       "                                                                    book_data_tokenized  \\\n",
       "0                             [the, unparalleled, adventures, of, one, hans, pfaall, 1]   \n",
       "2  [by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]   \n",
       "3         [of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]   \n",
       "4             [a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]   \n",
       "5        [variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]   \n",
       "\n",
       "                                                               book_data_tokenized_nlkt  \\\n",
       "0                             [the, unparalleled, adventures, of, one, hans, pfaall, 1]   \n",
       "2  [by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]   \n",
       "3         [of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]   \n",
       "4             [a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]   \n",
       "5        [variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]   \n",
       "\n",
       "                                                 book_data_nostop  \\\n",
       "0                [unparalleled, adventures, one, hans, pfaall, 1]   \n",
       "2           [late, accounts, rotterdam, city, seems, high, state]   \n",
       "3        [philosophical, excitement, indeed, phenomena, occurred]   \n",
       "4  [nature, completely, unexpectedso, entirely, novelso, utterly]   \n",
       "5        [variance, preconceived, opinionsas, leave, doubt, mind]   \n",
       "\n",
       "                                         book_data_stemmed  \\\n",
       "0              [unparallel, adventur, one, han, pfaall, 1]   \n",
       "2      [late, account, rotterdam, citi, seem, high, state]   \n",
       "3               [philosoph, excit, inde, phenomena, occur]   \n",
       "4  [natur, complet, unexpectedso, entir, novelso, utterli]   \n",
       "5      [varianc, preconceiv, opinionsa, leav, doubt, mind]   \n",
       "\n",
       "                                             book_data_lemmatized  \n",
       "0                  [unparalleled, adventure, one, han, pfaall, 1]  \n",
       "2            [late, account, rotterdam, city, seems, high, state]  \n",
       "3       [philosophical, excitement, indeed, phenomenon, occurred]  \n",
       "4  [nature, completely, unexpectedso, entirely, novelso, utterly]  \n",
       "5        [variance, preconceived, opinionsas, leave, doubt, mind]  "
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if Tokenized word is in Stopword \n",
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopword]\n",
    "    return text\n",
    "\n",
    "fullCorpus['book_data_nostop'] = fullCorpus['book_data_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "fullCorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the final set nonstopword list to get stem text\n",
    "# Stem text are like running = run run = run  \n",
    "# (issue ) runner = run (which is not right but stem does it)\n",
    "# it helps in reducing the corpus size given we are able to stem our words correctly ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_data</th>\n",
       "      <th>book_data_clean</th>\n",
       "      <th>book_data_tokenized</th>\n",
       "      <th>book_data_tokenized_nlkt</th>\n",
       "      <th>book_data_nostop</th>\n",
       "      <th>book_data_stemmed</th>\n",
       "      <th>book_data_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)</td>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1</td>\n",
       "      <td>[the, unparalleled, adventures, of, one, hans, pfaall, 1]</td>\n",
       "      <td>[the, unparalleled, adventures, of, one, hans, pfaall, 1]</td>\n",
       "      <td>[unparalleled, adventures, one, hans, pfaall, 1]</td>\n",
       "      <td>[unparallel, adventur, one, han, pfaall, 1]</td>\n",
       "      <td>[unparalleled, adventure, one, han, pfaall, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BY late accounts from Rotterdam, that city seems to be in a high state</td>\n",
       "      <td>BY late accounts from Rotterdam that city seems to be in a high state</td>\n",
       "      <td>[by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]</td>\n",
       "      <td>[by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]</td>\n",
       "      <td>[late, accounts, rotterdam, city, seems, high, state]</td>\n",
       "      <td>[late, account, rotterdam, citi, seem, high, state]</td>\n",
       "      <td>[late, account, rotterdam, city, seems, high, state]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of philosophical excitement. Indeed, phenomena have there occurred of</td>\n",
       "      <td>of philosophical excitement Indeed phenomena have there occurred of</td>\n",
       "      <td>[of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]</td>\n",
       "      <td>[of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]</td>\n",
       "      <td>[philosophical, excitement, indeed, phenomena, occurred]</td>\n",
       "      <td>[philosoph, excit, inde, phenomena, occur]</td>\n",
       "      <td>[philosophical, excitement, indeed, phenomenon, occurred]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a nature so completely unexpected--so entirely novel--so utterly at</td>\n",
       "      <td>a nature so completely unexpectedso entirely novelso utterly at</td>\n",
       "      <td>[a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]</td>\n",
       "      <td>[a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]</td>\n",
       "      <td>[nature, completely, unexpectedso, entirely, novelso, utterly]</td>\n",
       "      <td>[natur, complet, unexpectedso, entir, novelso, utterli]</td>\n",
       "      <td>[nature, completely, unexpectedso, entirely, novelso, utterly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>variance with preconceived opinions--as to leave no doubt on my mind</td>\n",
       "      <td>variance with preconceived opinionsas to leave no doubt on my mind</td>\n",
       "      <td>[variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]</td>\n",
       "      <td>[variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]</td>\n",
       "      <td>[variance, preconceived, opinionsas, leave, doubt, mind]</td>\n",
       "      <td>[varianc, preconceiv, opinionsa, leav, doubt, mind]</td>\n",
       "      <td>[variance, preconceived, opinionsas, leave, doubt, mind]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                book_data  \\\n",
       "0                     THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)   \n",
       "2  BY late accounts from Rotterdam, that city seems to be in a high state   \n",
       "3   of philosophical excitement. Indeed, phenomena have there occurred of   \n",
       "4     a nature so completely unexpected--so entirely novel--so utterly at   \n",
       "5    variance with preconceived opinions--as to leave no doubt on my mind   \n",
       "\n",
       "                                                         book_data_clean  \\\n",
       "0                       THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1   \n",
       "2  BY late accounts from Rotterdam that city seems to be in a high state   \n",
       "3    of philosophical excitement Indeed phenomena have there occurred of   \n",
       "4        a nature so completely unexpectedso entirely novelso utterly at   \n",
       "5     variance with preconceived opinionsas to leave no doubt on my mind   \n",
       "\n",
       "                                                                    book_data_tokenized  \\\n",
       "0                             [the, unparalleled, adventures, of, one, hans, pfaall, 1]   \n",
       "2  [by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]   \n",
       "3         [of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]   \n",
       "4             [a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]   \n",
       "5        [variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]   \n",
       "\n",
       "                                                               book_data_tokenized_nlkt  \\\n",
       "0                             [the, unparalleled, adventures, of, one, hans, pfaall, 1]   \n",
       "2  [by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]   \n",
       "3         [of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]   \n",
       "4             [a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]   \n",
       "5        [variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]   \n",
       "\n",
       "                                                 book_data_nostop  \\\n",
       "0                [unparalleled, adventures, one, hans, pfaall, 1]   \n",
       "2           [late, accounts, rotterdam, city, seems, high, state]   \n",
       "3        [philosophical, excitement, indeed, phenomena, occurred]   \n",
       "4  [nature, completely, unexpectedso, entirely, novelso, utterly]   \n",
       "5        [variance, preconceived, opinionsas, leave, doubt, mind]   \n",
       "\n",
       "                                         book_data_stemmed  \\\n",
       "0              [unparallel, adventur, one, han, pfaall, 1]   \n",
       "2      [late, account, rotterdam, citi, seem, high, state]   \n",
       "3               [philosoph, excit, inde, phenomena, occur]   \n",
       "4  [natur, complet, unexpectedso, entir, novelso, utterli]   \n",
       "5      [varianc, preconceiv, opinionsa, leav, doubt, mind]   \n",
       "\n",
       "                                             book_data_lemmatized  \n",
       "0                  [unparalleled, adventure, one, han, pfaall, 1]  \n",
       "2            [late, account, rotterdam, city, seems, high, state]  \n",
       "3       [philosophical, excitement, indeed, phenomenon, occurred]  \n",
       "4  [nature, completely, unexpectedso, entirely, novelso, utterly]  \n",
       "5        [variance, preconceived, opinionsas, leave, doubt, mind]  "
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ps is porterstemmer \n",
    "ps = nltk.PorterStemmer()\n",
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "fullCorpus['book_data_stemmed'] = fullCorpus['book_data_nostop'].apply(lambda x: stemming(x))\n",
    "\n",
    "fullCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "run\n",
      "runner\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('run'))\n",
    "print(ps.stem('running'))\n",
    "print(ps.stem('runner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing \n",
    "Lemmatizing is using vocabulary analysis of words to remove inflectional endings and return to the dictionary form of a word. So again, type, typed, and typing would all be simplified down to type, because that's the root of the word. Each variation carries the same meaning just with slightly different tense. \n",
    "\n",
    "##### Is Lemmatizing like stemming ? \n",
    "> The objective of both methods is to reduce the corpus size but they are doing it in just slightly different ways. In pratice, Lemmatizing is more accurate but is very intense and heavy computation  where is Stemming is light and fast. \n",
    "\n",
    "The goal of both is to condense derived words down into their base form, to reduce the corpus of words that the model's exposed to, and to explicitly correlate words with similar meaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "mean\n",
      "mango\n",
      "mean\n",
      "children\n",
      "child\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('meanness'))\n",
    "print(ps.stem('meaning'))\n",
    "print(ps.stem('mangoes'))\n",
    "print(ps.stem('meaning'))\n",
    "print(ps.stem('children'))\n",
    "print(ps.stem('child'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanness\n",
      "meaning\n",
      "mango\n",
      "mango\n",
      "child\n",
      "child\n",
      "seems\n"
     ]
    }
   ],
   "source": [
    "print(wn.lemmatize('meanness'))\n",
    "print(wn.lemmatize('meaning' ))\n",
    "print(wn.lemmatize('mangoes'))\n",
    "print(wn.lemmatize('mango'))\n",
    "print(wn.lemmatize('children'))\n",
    "print(wn.lemmatize('child'))\n",
    "print(wn.lemmatize('seems'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_data</th>\n",
       "      <th>book_data_clean</th>\n",
       "      <th>book_data_tokenized</th>\n",
       "      <th>book_data_tokenized_nlkt</th>\n",
       "      <th>book_data_nostop</th>\n",
       "      <th>book_data_stemmed</th>\n",
       "      <th>book_data_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)</td>\n",
       "      <td>THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1</td>\n",
       "      <td>[the, unparalleled, adventures, of, one, hans, pfaall, 1]</td>\n",
       "      <td>[the, unparalleled, adventures, of, one, hans, pfaall, 1]</td>\n",
       "      <td>[unparalleled, adventures, one, hans, pfaall, 1]</td>\n",
       "      <td>[unparallel, adventur, one, han, pfaall, 1]</td>\n",
       "      <td>[unparalleled, adventure, one, han, pfaall, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BY late accounts from Rotterdam, that city seems to be in a high state</td>\n",
       "      <td>BY late accounts from Rotterdam that city seems to be in a high state</td>\n",
       "      <td>[by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]</td>\n",
       "      <td>[by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]</td>\n",
       "      <td>[late, accounts, rotterdam, city, seems, high, state]</td>\n",
       "      <td>[late, account, rotterdam, citi, seem, high, state]</td>\n",
       "      <td>[late, account, rotterdam, city, seems, high, state]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of philosophical excitement. Indeed, phenomena have there occurred of</td>\n",
       "      <td>of philosophical excitement Indeed phenomena have there occurred of</td>\n",
       "      <td>[of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]</td>\n",
       "      <td>[of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]</td>\n",
       "      <td>[philosophical, excitement, indeed, phenomena, occurred]</td>\n",
       "      <td>[philosoph, excit, inde, phenomena, occur]</td>\n",
       "      <td>[philosophical, excitement, indeed, phenomenon, occurred]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a nature so completely unexpected--so entirely novel--so utterly at</td>\n",
       "      <td>a nature so completely unexpectedso entirely novelso utterly at</td>\n",
       "      <td>[a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]</td>\n",
       "      <td>[a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]</td>\n",
       "      <td>[nature, completely, unexpectedso, entirely, novelso, utterly]</td>\n",
       "      <td>[natur, complet, unexpectedso, entir, novelso, utterli]</td>\n",
       "      <td>[nature, completely, unexpectedso, entirely, novelso, utterly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>variance with preconceived opinions--as to leave no doubt on my mind</td>\n",
       "      <td>variance with preconceived opinionsas to leave no doubt on my mind</td>\n",
       "      <td>[variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]</td>\n",
       "      <td>[variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]</td>\n",
       "      <td>[variance, preconceived, opinionsas, leave, doubt, mind]</td>\n",
       "      <td>[varianc, preconceiv, opinionsa, leav, doubt, mind]</td>\n",
       "      <td>[variance, preconceived, opinionsas, leave, doubt, mind]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                book_data  \\\n",
       "0                     THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL (*1)   \n",
       "2  BY late accounts from Rotterdam, that city seems to be in a high state   \n",
       "3   of philosophical excitement. Indeed, phenomena have there occurred of   \n",
       "4     a nature so completely unexpected--so entirely novel--so utterly at   \n",
       "5    variance with preconceived opinions--as to leave no doubt on my mind   \n",
       "\n",
       "                                                         book_data_clean  \\\n",
       "0                       THE UNPARALLELED ADVENTURES OF ONE HANS PFAALL 1   \n",
       "2  BY late accounts from Rotterdam that city seems to be in a high state   \n",
       "3    of philosophical excitement Indeed phenomena have there occurred of   \n",
       "4        a nature so completely unexpectedso entirely novelso utterly at   \n",
       "5     variance with preconceived opinionsas to leave no doubt on my mind   \n",
       "\n",
       "                                                                    book_data_tokenized  \\\n",
       "0                             [the, unparalleled, adventures, of, one, hans, pfaall, 1]   \n",
       "2  [by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]   \n",
       "3         [of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]   \n",
       "4             [a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]   \n",
       "5        [variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]   \n",
       "\n",
       "                                                               book_data_tokenized_nlkt  \\\n",
       "0                             [the, unparalleled, adventures, of, one, hans, pfaall, 1]   \n",
       "2  [by, late, accounts, from, rotterdam, that, city, seems, to, be, in, a, high, state]   \n",
       "3         [of, philosophical, excitement, indeed, phenomena, have, there, occurred, of]   \n",
       "4             [a, nature, so, completely, unexpectedso, entirely, novelso, utterly, at]   \n",
       "5        [variance, with, preconceived, opinionsas, to, leave, no, doubt, on, my, mind]   \n",
       "\n",
       "                                                 book_data_nostop  \\\n",
       "0                [unparalleled, adventures, one, hans, pfaall, 1]   \n",
       "2           [late, accounts, rotterdam, city, seems, high, state]   \n",
       "3        [philosophical, excitement, indeed, phenomena, occurred]   \n",
       "4  [nature, completely, unexpectedso, entirely, novelso, utterly]   \n",
       "5        [variance, preconceived, opinionsas, leave, doubt, mind]   \n",
       "\n",
       "                                         book_data_stemmed  \\\n",
       "0              [unparallel, adventur, one, han, pfaall, 1]   \n",
       "2      [late, account, rotterdam, citi, seem, high, state]   \n",
       "3               [philosoph, excit, inde, phenomena, occur]   \n",
       "4  [natur, complet, unexpectedso, entir, novelso, utterli]   \n",
       "5      [varianc, preconceiv, opinionsa, leav, doubt, mind]   \n",
       "\n",
       "                                             book_data_lemmatized  \n",
       "0                  [unparalleled, adventure, one, han, pfaall, 1]  \n",
       "2            [late, account, rotterdam, city, seems, high, state]  \n",
       "3       [philosophical, excitement, indeed, phenomenon, occurred]  \n",
       "4  [nature, completely, unexpectedso, entirely, novelso, utterly]  \n",
       "5        [variance, preconceived, opinionsas, leave, doubt, mind]  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "fullCorpus['book_data_lemmatized'] = fullCorpus['book_data_nostop'].apply(lambda x: lemmatizing(x))\n",
    "\n",
    "fullCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# All Function at one place \n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7107, 6617)\n",
      "['0', '005484', '1', '10']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_counts = count_vect.fit_transform(fullCorpus['book_data'])\n",
    "print(X_counts.shape)  # How many rows are present and How many columns are present , i.e. How many unique word we have \n",
    "print(count_vect.get_feature_names()[1:5]) # All the Unique words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Document Terms Matrix with Column as Unique word and row number is the row in book. \n",
    "X_count_df= pd.DataFrame(X_counts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6607</th>\n",
       "      <th>6608</th>\n",
       "      <th>6609</th>\n",
       "      <th>6610</th>\n",
       "      <th>6611</th>\n",
       "      <th>6612</th>\n",
       "      <th>6613</th>\n",
       "      <th>6614</th>\n",
       "      <th>6615</th>\n",
       "      <th>6616</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6617 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  6607  \\\n",
       "0     0     0     0     1     0     0     0     0     0     0  ...     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   6608  6609  6610  6611  6612  6613  6614  6615  6616  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 6617 columns]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding name to column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9', '94808188', '948884', '9th', 'abandon', 'abbrevi', 'aberr', 'abid', 'abil', 'abject', 'abl', 'abnorm', 'abomin', 'abound', 'aboundher', 'abovenam', 'abroad', 'abrupt', 'abruptli', 'absenc', 'absent', 'absolut', 'absorb', 'abstract', 'abstractlet', 'abstrus', 'absurd', 'absurdli', 'abund', 'abundantli', 'abus', 'abyss', 'acceler', 'accent', 'accept', 'access', 'accid', 'accident', 'accidenti', 'accidentsay', 'acclam', 'accompani', 'accomplic', 'accomplish', 'accomplishedbut', 'accomplishedor', 'accord', 'accordingli', 'accost', 'account', 'accoutr', 'accru', 'accumul', 'accur', 'accuraci', 'accurs', 'accus', 'accustom', 'acet', 'achiev', 'achil', 'acid', 'acknowledg', 'acquaint', 'acquir', 'across', 'act', 'action', 'activ', 'actor', 'actual', 'acumen', 'acut', 'ad', 'adam', 'adapt', 'add', 'addit', 'address', 'adduc', 'adelaid', 'adequ', 'adher', 'adieu', 'adjoin', 'adjust', 'admir', 'admiss', 'admit', 'admitt', 'adolph', 'adopt', 'ador', 'adrift', 'aduanturi', 'advanc', 'advantag', 'advent', 'adventiti', 'adventur']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6617"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(count_vect.get_feature_names()[100:200])\n",
    "len(count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>005484</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>1000</th>\n",
       "      <th>10600</th>\n",
       "      <th>1080</th>\n",
       "      <th>10th</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>zealou</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zone</th>\n",
       "      <th>zufal</th>\n",
       "      <th>zusammen</th>\n",
       "      <th>Ã¦rial</th>\n",
       "      <th>Ã¦ronaut</th>\n",
       "      <th>Ã¦rostat</th>\n",
       "      <th>Ã©meut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 6617 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  005484  1  10  1000  10600  1080  10th  11  ...  zealou  zenith  \\\n",
       "0  0  0       0  1   0     0      0     0     0   0  ...       0       0   \n",
       "1  0  0       0  0   0     0      0     0     0   0  ...       0       0   \n",
       "2  0  0       0  0   0     0      0     0     0   0  ...       0       0   \n",
       "3  0  0       0  0   0     0      0     0     0   0  ...       0       0   \n",
       "4  0  0       0  0   0     0      0     0     0   0  ...       0       0   \n",
       "5  0  0       0  0   0     0      0     0     0   0  ...       0       0   \n",
       "6  0  0       0  0   0     0      0     0     0   0  ...       0       0   \n",
       "7  0  0       0  0   0     0      0     0     0   0  ...       0       0   \n",
       "8  0  0       0  0   0     0      0     0     0   0  ...       0       0   \n",
       "9  0  0       0  0   0     0      0     0     0   0  ...       0       0   \n",
       "\n",
       "   zodiac  zone  zufal  zusammen  Ã¦rial  Ã¦ronaut  Ã¦rostat  Ã©meut  \n",
       "0       0     0      0         0      0        0        0      0  \n",
       "1       0     0      0         0      0        0        0      0  \n",
       "2       0     0      0         0      0        0        0      0  \n",
       "3       0     0      0         0      0        0        0      0  \n",
       "4       0     0      0         0      0        0        0      0  \n",
       "5       0     0      0         0      0        0        0      0  \n",
       "6       0     0      0         0      0        0        0      0  \n",
       "7       0     0      0         0      0        0        0      0  \n",
       "8       0     0      0         0      0        0        0      0  \n",
       "9       0     0      0         0      0        0        0      0  \n",
       "\n",
       "[10 rows x 6617 columns]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add columnname to Features / Terms \n",
    "X_count_df.columns = count_vect.get_feature_names()\n",
    "X_count_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>005484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Terms  Count\n",
       "1       0      1\n",
       "2  005484      1\n",
       "3       1      9\n",
       "4      10      3\n",
       "5    1000      1"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(count_vect.get_feature_names()[1:5])\n",
    "# print(X_counts.toarray()[1:5])\n",
    "# Get the Term frq in Dataframe \n",
    "term = count_vect.get_feature_names()\n",
    "count = X_counts.toarray().sum(axis=0)\n",
    "book_data_tfdf = pd.DataFrame({'Terms': term,'Count':count })\n",
    "book_data_tfdf = book_data_tfdf[book_data_tfdf.Terms!=\"\"]\n",
    "book_data_tfdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>one</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>time</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>found</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5071</th>\n",
       "      <td>say</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>even</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>appear</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>bodi</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>first</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>day</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>two</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5888</th>\n",
       "      <td>thu</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>mean</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>littl</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>de</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>made</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>howev</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>without</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6443</th>\n",
       "      <td>well</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>must</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>balloon</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Terms  Count\n",
       "4072      one    264\n",
       "5907     time    159\n",
       "2391    found    155\n",
       "5071      say    124\n",
       "2039     even    115\n",
       "384    appear    114\n",
       "722      bodi    112\n",
       "2272    first    112\n",
       "1433      day    110\n",
       "6074      two    110\n",
       "5888      thu    103\n",
       "3634     mean    102\n",
       "3454    littl    102\n",
       "1438       de    102\n",
       "3540     made    102\n",
       "2873    howev    100\n",
       "6530  without     98\n",
       "6443     well     97\n",
       "3841     must     97\n",
       "546   balloon     96"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_data_tfdf.sort_values(by=['Count'],ascending=False,inplace=True)\n",
    "book_data_tfdf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "97005\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "print(type(tokens))\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 97,005 tokens.  Tokens includes words and punctuation.  (Spaces and new line characters are removed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = nltk.Text(tokens)\n",
    "#convert all words to lower case, and remove puncutation\n",
    "words = [w.lower() for w in tokens]\n",
    "#words = [w.strip() for w in words]\n",
    "words = [w.strip('_') for w in words]\n",
    "words = [w.strip('*') for w in words]\n",
    "#words = [w.strip('.') for w in words]\n",
    "#words = [w.strip('!') for w in words]\n",
    "#words = [w.strip('&') for w in words]\n",
    "#words = [w.strip('?') for w in words]\n",
    "#words = [w.strip(';') for w in words]\n",
    "#words = [w.strip('-') for w in words]\n",
    "#words = [w.strip(',') for w in words]\n",
    "#words = [w.strip('(') for w in words]\n",
    "#words = [w.strip(')') for w in words]\n",
    "#words = [w.strip(':') for w in words]\n",
    "#words = [w.strip('[') for w in words]\n",
    "#words = [w.strip(']') for w in words]\n",
    "#words = [w.strip('\"') for w in words]\n",
    "#words = [w.strip('') for w in words]\n",
    "#words = [w.strip('â€™') for w in words]\n",
    "#words = [w.strip('â€') for w in words]\n",
    "#remove numbers and punctuation\n",
    "nonPunct = re.compile('.*[A-Za-z].*')\n",
    "words = [w for w in words if nonPunct.match(w)]\n",
    "#remove stop words\n",
    "words = [word for word in words if word not in sw.words('english')]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39186 words present in the corpus.\n"
     ]
    }
   ],
   "source": [
    "print('There are '+ str(len(words)) + ' words present in the corpus.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-satisfying',\n",
       " '.fleet',\n",
       " '10th',\n",
       " '11th',\n",
       " '12th',\n",
       " '13th',\n",
       " '14th',\n",
       " '15th',\n",
       " '16th',\n",
       " '17th',\n",
       " '18th',\n",
       " '19th',\n",
       " '3d',\n",
       " '3h',\n",
       " '4th',\n",
       " '5th',\n",
       " '6th',\n",
       " '6th_.',\n",
       " '7th',\n",
       " '8th',\n",
       " '9_th',\n",
       " '9th',\n",
       " 'a-kimbo',\n",
       " 'a.',\n",
       " 'a.m.',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abbreviation',\n",
       " 'aberration',\n",
       " 'abide',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'abnormal',\n",
       " 'abominable',\n",
       " 'abound',\n",
       " 'abounding',\n",
       " 'about.',\n",
       " 'above-named',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absented',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'abstract',\n",
       " 'abstracted',\n",
       " 'abstraction',\n",
       " 'abstruse',\n",
       " 'abstruseness',\n",
       " 'absurd',\n",
       " 'absurdly',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abyss',\n",
       " 'abysses',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accents',\n",
       " 'accepted',\n",
       " 'accession',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidents',\n",
       " 'acclamation',\n",
       " 'accompanied',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplice',\n",
       " 'accomplices',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishing',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accosted',\n",
       " 'account',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accoutrements',\n",
       " 'accruing',\n",
       " 'accumulating',\n",
       " 'accumulations',\n",
       " 'accumulative',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accursed',\n",
       " 'accusation',\n",
       " 'accustomed',\n",
       " 'acetous',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achilles',\n",
       " 'acid',\n",
       " 'acknowledge',\n",
       " 'acknowledging',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquainted',\n",
       " 'acquired',\n",
       " 'acquirement',\n",
       " 'acquires',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activity',\n",
       " 'actors',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'acumen',\n",
       " 'acute',\n",
       " 'acutely',\n",
       " 'adam',\n",
       " 'adapted',\n",
       " 'adapting',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'addressed',\n",
       " 'adduce',\n",
       " 'adduced',\n",
       " 'adelaide',\n",
       " 'adequate',\n",
       " 'adherence',\n",
       " 'adieu',\n",
       " 'adjoining',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'admired',\n",
       " 'admirers',\n",
       " 'admiring',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admittance',\n",
       " 'admitted',\n",
       " 'admitting',\n",
       " 'adolphe',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adored',\n",
       " 'adrift',\n",
       " 'aduanturier',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advances',\n",
       " 'advantage',\n",
       " 'advantageous',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'adventitious',\n",
       " 'adventure',\n",
       " 'adventurer',\n",
       " 'adventurers',\n",
       " 'adventures',\n",
       " 'advert',\n",
       " 'advertisement',\n",
       " 'advertiser',\n",
       " 'advice',\n",
       " 'advisable',\n",
       " 'advoue',\n",
       " 'aerial',\n",
       " 'aeronaut',\n",
       " 'aeronautic',\n",
       " 'aeronauts',\n",
       " 'aerostation',\n",
       " 'afar',\n",
       " 'affair',\n",
       " 'affaire',\n",
       " 'affairs',\n",
       " 'affected',\n",
       " 'affectedly',\n",
       " 'affectionate',\n",
       " 'affianced',\n",
       " 'affidavits',\n",
       " 'affinity',\n",
       " 'affixed',\n",
       " 'afford',\n",
       " 'afforded',\n",
       " 'affording',\n",
       " 'affright',\n",
       " 'afloat',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africans',\n",
       " 'aft',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'again.',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aghast',\n",
       " 'agility',\n",
       " 'agitated',\n",
       " 'agitating',\n",
       " 'agitation',\n",
       " 'ago',\n",
       " 'ago.',\n",
       " 'agog',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreeably',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'ague',\n",
       " 'ah',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aided',\n",
       " 'aides-de-camp',\n",
       " 'aiding',\n",
       " 'ails',\n",
       " 'aim',\n",
       " 'ainsworth',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'air-tight',\n",
       " 'ajar',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alarmingly',\n",
       " 'alas',\n",
       " 'albatross',\n",
       " 'alberto',\n",
       " 'ale',\n",
       " 'alexander',\n",
       " 'alexandre',\n",
       " 'alfonzo',\n",
       " 'alger',\n",
       " 'alien',\n",
       " 'alight',\n",
       " 'aliment',\n",
       " 'alive',\n",
       " 'all.',\n",
       " 'allayed.',\n",
       " 'alley',\n",
       " 'allow',\n",
       " 'allowances',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allude',\n",
       " 'alluded',\n",
       " 'allusion',\n",
       " 'allusions',\n",
       " 'alluvial',\n",
       " 'almighty',\n",
       " 'almost',\n",
       " 'aloft',\n",
       " 'alone',\n",
       " 'alone.',\n",
       " 'along',\n",
       " 'alphabet',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alteration',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternations',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altitude',\n",
       " 'altitudes',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'ambiguity',\n",
       " 'ambitious',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amid',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amounting',\n",
       " 'amounts',\n",
       " 'amour',\n",
       " 'amphitheatre',\n",
       " 'ample',\n",
       " 'amply',\n",
       " 'amsterdam',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusements',\n",
       " 'amusing',\n",
       " 'analogical',\n",
       " 'analogous',\n",
       " 'analogy',\n",
       " 'analyse',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analytic',\n",
       " 'analytical',\n",
       " 'anan',\n",
       " 'anatomical',\n",
       " 'anatomists',\n",
       " 'ancestors',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'ancients',\n",
       " 'anderson',\n",
       " 'andree',\n",
       " 'andrÃ©e',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'anglois',\n",
       " 'angrily',\n",
       " 'angry',\n",
       " 'angular',\n",
       " 'animadversion',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'ankle',\n",
       " 'ankles',\n",
       " 'annals',\n",
       " 'annihilation',\n",
       " 'announce',\n",
       " 'announcement',\n",
       " 'announcing',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoys',\n",
       " 'annually',\n",
       " 'anomalous',\n",
       " 'anomaly',\n",
       " 'anon',\n",
       " 'another',\n",
       " 'ansichten',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'antagonistical',\n",
       " 'antennÃ¦',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'anticipations',\n",
       " 'antioch',\n",
       " 'antiochia',\n",
       " 'antiochus',\n",
       " 'antipathies',\n",
       " 'antiquarians',\n",
       " 'antiquated',\n",
       " 'antique',\n",
       " 'antiquities',\n",
       " 'antiquity.',\n",
       " 'antiquum',\n",
       " 'anxieties',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'anything',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apartments',\n",
       " 'apathy',\n",
       " 'ape',\n",
       " 'aperture',\n",
       " 'apex',\n",
       " 'aphelion',\n",
       " 'apothegm',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'apparatus',\n",
       " 'apparel',\n",
       " 'apparent',\n",
       " 'apparent.',\n",
       " 'apparently',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearance.',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appellation',\n",
       " 'appendages',\n",
       " 'appended',\n",
       " 'appennines',\n",
       " 'appertain',\n",
       " 'appertains',\n",
       " 'apples',\n",
       " 'appliances',\n",
       " 'applicable',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'appointed',\n",
       " 'appreciable',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciation',\n",
       " 'apprehended',\n",
       " 'apprehending',\n",
       " 'apprehension',\n",
       " 'apprehensions',\n",
       " 'apprehensive',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'april',\n",
       " 'apsides',\n",
       " 'apt',\n",
       " 'aqua',\n",
       " 'aqueduct',\n",
       " 'arabesque',\n",
       " 'arcadians',\n",
       " 'arch',\n",
       " 'archimedean',\n",
       " 'archipelago',\n",
       " 'architecture',\n",
       " 'arctic',\n",
       " 'ardor',\n",
       " 'area',\n",
       " 'argelais',\n",
       " 'argue',\n",
       " 'argued',\n",
       " 'argues',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'aridity',\n",
       " 'aright',\n",
       " 'arise',\n",
       " 'arisen',\n",
       " 'arises',\n",
       " 'arising',\n",
       " 'arithmetic',\n",
       " 'arithmetical',\n",
       " 'arm',\n",
       " 'arm-chair',\n",
       " 'arm-chairs',\n",
       " 'armed',\n",
       " 'armorial',\n",
       " 'arms',\n",
       " 'arose',\n",
       " 'around',\n",
       " 'arouse',\n",
       " 'aroused',\n",
       " 'arousing',\n",
       " 'arrange',\n",
       " 'arranged',\n",
       " 'arrangement',\n",
       " 'arrangements',\n",
       " 'arranges',\n",
       " 'arranging',\n",
       " 'arrant',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arrests',\n",
       " 'arrival',\n",
       " 'arrivals',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrow',\n",
       " 'arrowy',\n",
       " 'art',\n",
       " 'art.',\n",
       " 'arter',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'artizan',\n",
       " 'ascend',\n",
       " 'ascended',\n",
       " 'ascending',\n",
       " 'ascension',\n",
       " 'ascensions',\n",
       " 'ascent',\n",
       " 'ascertain',\n",
       " 'ascertained',\n",
       " 'ascertaining',\n",
       " 'ashamed',\n",
       " 'ashimah',\n",
       " 'ashore',\n",
       " 'asiatic',\n",
       " 'asiatics',\n",
       " 'ask',\n",
       " 'askant',\n",
       " 'asked',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'assassin',\n",
       " 'assassinated',\n",
       " 'assassination',\n",
       " 'assassinations',\n",
       " 'assassins',\n",
       " 'assassins.',\n",
       " 'assemblage',\n",
       " 'assembled',\n",
       " 'assembly',\n",
       " 'assent',\n",
       " 'assented',\n",
       " 'assert',\n",
       " 'asserted',\n",
       " 'asserting',\n",
       " 'assertion',\n",
       " 'assertions',\n",
       " 'asserts',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assisted',\n",
       " 'associate',\n",
       " 'associates',\n",
       " 'assorted',\n",
       " 'assorting',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assure',\n",
       " 'assured',\n",
       " 'assuredly',\n",
       " 'assures',\n",
       " 'astonish',\n",
       " 'astonished',\n",
       " 'astonishment',\n",
       " 'astounding',\n",
       " 'astride',\n",
       " 'astrology',\n",
       " 'astronomer',\n",
       " 'astronomers',\n",
       " 'astronomical',\n",
       " 'astronomy',\n",
       " 'asunder',\n",
       " 'atalanta.',\n",
       " 'ate',\n",
       " 'athwart',\n",
       " 'atlantic',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atomies',\n",
       " 'atoms',\n",
       " 'atrocious',\n",
       " 'atrocities',\n",
       " 'atrocity',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attainable',\n",
       " 'attained',\n",
       " 'attaining',\n",
       " 'attainment',\n",
       " 'attains',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attend',\n",
       " 'attendance',\n",
       " 'attendant',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attentions',\n",
       " 'attentive',\n",
       " 'attentively',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attracting',\n",
       " 'attraction',\n",
       " 'attractions',\n",
       " 'attributable',\n",
       " 'attribute',\n",
       " 'attributed',\n",
       " 'attributing',\n",
       " 'atys',\n",
       " 'au',\n",
       " 'audacious',\n",
       " 'augment',\n",
       " 'augmented',\n",
       " 'augmenting',\n",
       " 'auguste',\n",
       " 'aujourd',\n",
       " 'aunt',\n",
       " 'auoir',\n",
       " 'aurelian',\n",
       " 'austere',\n",
       " 'authentic',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'authors',\n",
       " 'autocrats',\n",
       " 'autrem',\n",
       " 'autres',\n",
       " 'avail',\n",
       " 'availed',\n",
       " 'availing',\n",
       " 'average',\n",
       " 'averse',\n",
       " 'aversion',\n",
       " 'avisson',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'avoirdupois',\n",
       " 'await',\n",
       " 'awaited',\n",
       " 'awaiting',\n",
       " 'awake',\n",
       " 'awakened',\n",
       " 'awakening',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awkwardly',\n",
       " 'awoke',\n",
       " 'axis',\n",
       " 'ay',\n",
       " 'b',\n",
       " 'b.',\n",
       " 'babel',\n",
       " 'baboon',\n",
       " 'bacchanalian',\n",
       " 'back',\n",
       " 'back-ground',\n",
       " 'back.',\n",
       " 'backs',\n",
       " 'bad',\n",
       " 'bade',\n",
       " 'bag',\n",
       " 'bags',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balbec',\n",
       " 'ball',\n",
       " 'ballast',\n",
       " 'balloon',\n",
       " 'balloon-hoax',\n",
       " 'balloons',\n",
       " 'band',\n",
       " 'bandage',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'banking',\n",
       " 'banks',\n",
       " 'banter',\n",
       " 'bantry',\n",
       " 'bar',\n",
       " 'barber',\n",
       " 'bare',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'barge',\n",
       " 'barge-office',\n",
       " 'bargeman',\n",
       " 'bargemen',\n",
       " 'bark',\n",
       " 'barometer',\n",
       " 'barometers',\n",
       " 'barrel',\n",
       " 'barrels',\n",
       " 'barricade',\n",
       " 'barriÃ¨re',\n",
       " 'bars',\n",
       " 'base',\n",
       " 'based',\n",
       " 'baseless',\n",
       " 'basement',\n",
       " 'basin',\n",
       " 'basket',\n",
       " 'batavia',\n",
       " 'bath',\n",
       " 'battle-door',\n",
       " 'battle-lanterns',\n",
       " 'battlement',\n",
       " 'bawling',\n",
       " 'bay',\n",
       " 'bayonet',\n",
       " 'be.',\n",
       " 'beach',\n",
       " 'beam-ends',\n",
       " 'bear',\n",
       " 'bearer',\n",
       " 'bearing',\n",
       " 'bearings',\n",
       " 'bears',\n",
       " 'beast',\n",
       " 'beasts',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beating',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'beauvais',\n",
       " 'beaver',\n",
       " 'became',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'bed-posts',\n",
       " 'bed-room',\n",
       " 'bedecked',\n",
       " 'beds',\n",
       " 'bedstead',\n",
       " 'bee',\n",
       " 'bee-line',\n",
       " 'beetle',\n",
       " 'befallen',\n",
       " 'before.',\n",
       " 'befriends',\n",
       " 'beg',\n",
       " 'began',\n",
       " 'begebenheit',\n",
       " 'begebenheiten',\n",
       " 'begged',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'beguile',\n",
       " 'begun',\n",
       " 'behaved',\n",
       " 'beheld',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'behooved',\n",
       " 'bei',\n",
       " 'beings',\n",
       " 'belabor',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'believe.',\n",
       " 'believed',\n",
       " 'believes',\n",
       " 'believing',\n",
       " 'belles',\n",
       " 'bellowing',\n",
       " 'bellows',\n",
       " 'bellows-mender',\n",
       " 'belong',\n",
       " 'belonged',\n",
       " 'belonging',\n",
       " 'belongs',\n",
       " 'beloved',\n",
       " 'belted',\n",
       " 'bending',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'benoist',\n",
       " 'bent',\n",
       " 'bentinck',\n",
       " 'bergerac',\n",
       " 'berlin',\n",
       " 'berry',\n",
       " 'beseech',\n",
       " 'beset',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'besieged',\n",
       " 'besmeared',\n",
       " 'bespeak',\n",
       " 'besprinkled',\n",
       " 'bessop',\n",
       " 'best',\n",
       " 'best-constructed',\n",
       " 'bestir',\n",
       " 'bestow',\n",
       " 'bestowed',\n",
       " 'bethought',\n",
       " 'betook',\n",
       " 'betray',\n",
       " 'betrayal',\n",
       " 'betrayed',\n",
       " 'betrayer',\n",
       " 'betrays',\n",
       " 'betrothed',\n",
       " 'better',\n",
       " 'betting',\n",
       " 'betty',\n",
       " 'bewilder',\n",
       " 'bewildered',\n",
       " 'bewildering',\n",
       " 'beyond',\n",
       " 'bi-chloride',\n",
       " 'bi-part',\n",
       " 'bias',\n",
       " 'bible',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'bigness',\n",
       " 'billet',\n",
       " 'billow',\n",
       " 'billows',\n",
       " 'bin',\n",
       " 'biot',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birth',\n",
       " 'bishop',\n",
       " 'bison',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'bitten',\n",
       " 'bitter',\n",
       " 'bitterest',\n",
       " 'bitterly',\n",
       " 'bivalve',\n",
       " 'bizarre',\n",
       " 'bizarrerie',\n",
       " 'black',\n",
       " 'blacker',\n",
       " 'blackguard',\n",
       " 'blackguards',\n",
       " 'blackness',\n",
       " 'blade',\n",
       " 'blame',\n",
       " 'blanc',\n",
       " 'blank',\n",
       " 'blankets',\n",
       " 'blas',\n",
       " 'blast',\n",
       " 'blaze',\n",
       " 'blazing',\n",
       " 'bleed',\n",
       " 'bleeding',\n",
       " 'blend',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blew',\n",
       " 'blieve',\n",
       " 'blind',\n",
       " 'blockhead.',\n",
       " 'blocks',\n",
       " 'blood',\n",
       " 'blood-red',\n",
       " 'blood-vessels',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blows',\n",
       " 'blue',\n",
       " 'blunderbuss',\n",
       " 'blundering',\n",
       " 'blunders',\n",
       " 'blunt',\n",
       " 'board',\n",
       " 'boarded',\n",
       " 'boasted',\n",
       " 'boat',\n",
       " 'boats',\n",
       " 'boded',\n",
       " 'bodies',\n",
       " 'bodily',\n",
       " 'body',\n",
       " 'body.',\n",
       " 'bois',\n",
       " 'boisterously',\n",
       " 'bold',\n",
       " 'boldly',\n",
       " 'boldness',\n",
       " 'bolted',\n",
       " 'bolts',\n",
       " 'bombay',\n",
       " 'bon',\n",
       " 'bones',\n",
       " 'bonfire',\n",
       " 'bonnet',\n",
       " 'bonnet-ribbon',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'books',\n",
       " 'bookseller',\n",
       " 'booming',\n",
       " 'booms',\n",
       " 'boon',\n",
       " 'boosed',\n",
       " 'boot',\n",
       " 'boots',\n",
       " 'booty',\n",
       " 'bordeaux',\n",
       " 'border',\n",
       " 'bordered',\n",
       " 'borders',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'born',\n",
       " 'borne',\n",
       " 'borneo',\n",
       " 'bornese',\n",
       " 'borrow',\n",
       " 'bosom',\n",
       " 'bosoms',\n",
       " 'bottle',\n",
       " 'bottles',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bouleversement',\n",
       " 'boulogne',\n",
       " 'bound',\n",
       " 'boundary',\n",
       " 'boundless',\n",
       " 'bounds',\n",
       " 'bout',\n",
       " 'bow',\n",
       " 'bow-knot',\n",
       " 'bowed',\n",
       " 'bowels',\n",
       " 'bower',\n",
       " 'bowl',\n",
       " 'bows',\n",
       " 'box',\n",
       " 'boxes',\n",
       " 'boy',\n",
       " 'boyish',\n",
       " 'boys',\n",
       " 'brain',\n",
       " 'brains',\n",
       " 'brambles',\n",
       " 'branch',\n",
       " 'branches',\n",
       " 'brandy',\n",
       " 'brass',\n",
       " 'brave',\n",
       " 'bravo',\n",
       " 'breaches',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breakers',\n",
       " 'breaking',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'breathed',\n",
       " 'breathing',\n",
       " 'breeches',\n",
       " 'breeze',\n",
       " 'brevity',\n",
       " 'brewster',\n",
       " 'brick',\n",
       " 'bride',\n",
       " 'brief',\n",
       " 'briefly',\n",
       " 'bright',\n",
       " 'brightened',\n",
       " 'brightest',\n",
       " 'brilliancy',\n",
       " 'brilliant',\n",
       " 'brilliantly',\n",
       " 'brim',\n",
       " 'bring',\n",
       " 'bringhurst',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'brink',\n",
       " 'bristly',\n",
       " 'bristol',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'broad',\n",
       " 'brochures',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'broomstick',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought']"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(words))\n",
    "vocab[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('upon', 378),\n",
       " ('one', 266),\n",
       " ('could', 219),\n",
       " ('would', 219),\n",
       " ('found', 147),\n",
       " ('us', 138),\n",
       " ('great', 124),\n",
       " ('time', 123),\n",
       " ('much', 120),\n",
       " ('first', 112),\n",
       " ('two', 110),\n",
       " ('thus', 106),\n",
       " ('say', 105),\n",
       " ('little', 102),\n",
       " ('made', 102),\n",
       " ('however', 101),\n",
       " ('well', 100),\n",
       " ('without', 99),\n",
       " ('must', 99),\n",
       " ('even', 97),\n",
       " ('three', 97),\n",
       " ('said', 95),\n",
       " ('balloon', 92),\n",
       " ('let', 90),\n",
       " ('may', 90),\n",
       " ('de', 88),\n",
       " ('body', 86),\n",
       " ('might', 86),\n",
       " ('far', 83),\n",
       " ('whole', 78),\n",
       " ('marie', 75),\n",
       " ('nothing', 74),\n",
       " ('although', 74),\n",
       " ('earth', 73),\n",
       " ('point', 72),\n",
       " ('still', 71),\n",
       " ('yet', 71),\n",
       " ('feet', 71),\n",
       " ('head', 69),\n",
       " ('day', 68),\n",
       " ('means', 67),\n",
       " ('see', 67),\n",
       " ('left', 66),\n",
       " ('indeed', 64),\n",
       " ('every', 64),\n",
       " ('corpse', 64),\n",
       " ('long', 63),\n",
       " ('within', 63),\n",
       " ('manner', 60),\n",
       " ('man', 60)]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(words)\n",
    "most_common_200 = fdist.most_common(200)\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8713"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_words = set(words)\n",
    "len(uniq_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8,713 unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text= nltk.Text(words)\n",
    "text.dispersion_plot([\"upon\", \"one\", \"could\", \"corpse\", \"balloon\"])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dispersion plot above shows some of the most common words in the corpus.  The most common words are 'upon,' 'one,' and 'could' and they are present fairly uniformly throughout the text.  Since Poe is known for frightful stories, we also looked at the use of word 'corpse,' which is only present in the second half of the corpus.  The word 'balloon' was very common.  This was a surprise and it is present at the beginning and end of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
