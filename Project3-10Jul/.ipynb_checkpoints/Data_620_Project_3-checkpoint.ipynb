{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA_620: Project 3 (Text Classifier)\n",
    "<b>GROUP3: </b>\n",
    "\n",
    "+ Md. Jalal Uddin\n",
    "+ Rajwant Mishra\n",
    "+ Sarah Wigodsky\n",
    "\n",
    "[Youtube](https://youtu.be/7txtVB1-Sds)\n",
    "\n",
    "For this project, please work with the entire class as one collaborative group! Your project should be submitted (as a Jupyter Notebook via GitHub) by end of the due date. The group should present their code and findings in our meetup. The ability to be an effective member of a virtual team is highly valued in the data science job market.\n",
    "\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can.\n",
    "Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the devtest set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. \n",
    "\n",
    "How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "\n",
    "Source: Natural Language Processing with Python, exercise 6.10.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Building data set: Using nltk function we have build gender data set called \"Gender_names\" here. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\Swigo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "from nltk.classify import apply_features\n",
    "nltk.download('names')\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "We are going to build the dataset for our Gender Classifier with Male.txt and Female.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "[(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(Gender_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Male: 2943 and Female: 5001 in dataset of size: 7944.\n"
     ]
    }
   ],
   "source": [
    "Gender_names[0:10] #show the names with gender. \n",
    "len(Gender_names)\n",
    "Gender_names_g= [g for (n,g) in Gender_names]\n",
    "Gender_names_m = Gender_names_g.count('male')\n",
    "Gender_names_f = Gender_names_g.count('female')\n",
    "print(\"Total Male: {} and Female: {} in dataset of size: {}.\".format(Gender_names_m,Gender_names_f,len(Gender_names_g)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Identification Features\n",
    "Male and female names have distinct characteristics such as names ending in a, e, and i are likely to be female, while names ending in k, o, r, s, and t are likely to be male. We have build a classifier to model these differences more precisely. We will look for the last letter of a given name. (Source: NLP book page 222-223) \n",
    "\n",
    "### A. Base Gender Features: \n",
    "A classifer which focuses on Last letter of the words to identify if name is Female or Male. (Works with Last letter of the name.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features_base(word):\n",
    "    return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'e'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features_base('Justine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A 1. Train and Test featuresets using *`gender_features_base`*\n",
    "Now we will divide the resulting list of feature sets into a `training` set and a `test` set after applying the feature extractor `gender_features_base` to process the `Gender_names` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with last letter [gender_features_base]:0.73\n"
     ]
    }
   ],
   "source": [
    "featuresets_base = [(gender_features_base(n), g) for (n,g) in Gender_names]\n",
    "train_set, test_set = featuresets_base[500:], featuresets_base[:500]\n",
    "classifier_base = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy_base= nltk.classify.accuracy(classifier_base, test_set)\n",
    "print (\"Accuracy with last letter [gender_features_base]:{}\".format(accuracy_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'last_letter': 'e'}, 'female')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Featrues output for Ref.\n",
    "featuresets_base[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the classifer output with *Romeo* and *Trinity*, and the Identify the some of the *more informative features*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name 'Romeo' which is Male and our classifer guess it as: male\n",
      "Name 'Trinity' which is Female and our classifer guess it as: female\n"
     ]
    }
   ],
   "source": [
    "print (\"Name 'Romeo' which is Male and our classifer guess it as:\",classifier_base.classify(gender_features_base('Romeo'))) #male\n",
    "print (\"Name 'Trinity' which is Female and our classifer guess it as:\",classifier_base.classify(gender_features_base('Trinity'))) #female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     35.8 : 1.0\n",
      "             last_letter = 'k'              male : female =     31.6 : 1.0\n",
      "             last_letter = 'p'              male : female =     20.8 : 1.0\n",
      "             last_letter = 'f'              male : female =     17.2 : 1.0\n",
      "             last_letter = 'v'              male : female =     11.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier_base.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A 2. Featureset to Dataframe\n",
    "\n",
    "Converting featuresets_base to dataframe, this will help us plot the frquency graph of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LastLetter</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LastLetter  Gender\n",
       "0          a  female\n",
       "1          r    male\n",
       "2          e  female\n",
       "3          r    male\n",
       "4          t    male"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gf = pd.DataFrame(featuresets_base, columns=['Letter','Gender'])\n",
    "df_gf['LastLetter'] = df_gf['Letter'].apply(lambda x: x['last_letter'])\n",
    "df_gf = df_gf[['LastLetter','Gender']]\n",
    "df_gf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "female = df_gf[df_gf['Gender']=='female']\n",
    "male = df_gf[df_gf['Gender']=='male']\n",
    "\n",
    "female = female.groupby('LastLetter').count().reset_index(drop=False)\n",
    "female['percent'] = female['Gender']*100/5001\n",
    "female = pd.DataFrame(female)\n",
    "female = female.iloc[1:,:]\n",
    "\n",
    "male = male.groupby('LastLetter').count().reset_index(drop=False)\n",
    "male['percent'] = male['Gender']*100/2943\n",
    "male = pd.DataFrame(male)\n",
    "\n",
    "data_f = go.Bar(\n",
    "            x=female['LastLetter'],\n",
    "            y=female['percent'],\n",
    "            name='female'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "data_m = go.Bar(\n",
    "            x=male['LastLetter'],\n",
    "            y=male['percent'],\n",
    "            name='male'\n",
    ")\n",
    "\n",
    "data = [data_m, data_f]\n",
    "layout = go.Layout(\n",
    "    title='Percentage of Last Letters in Names by Gender',\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='grouped-bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lastletter.png\" width=\"800\">\n",
    "The graph above shows the prevelance of each letter according to gender.  The last letter of a and e are much more common among females and the last letter of n, s and t are more common for males."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above displays the frequency of names ending in different letters according to gender.  The letter a is the most common last letter for female names and is very uncommon as a last letter in male names.  The letter e is a common last letter for males and females.  The letter s is more common for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with large corpora, we will use  use the function\n",
    "**nltk.classify.apply_features** which does not store all the feature sets in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'last_letter': 'k'}, 'male'), ({'last_letter': 'n'}, 'male'), ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### nltk.classify.apply_features which does not store all the feature sets in memory\n",
    "train_set = apply_features(gender_features_base, Gender_names[500:])\n",
    "test_set = apply_features(gender_features_base, Gender_names[:500])\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Gender Features A to Z : \n",
    "\n",
    "We are creating another Model which would be using the **Firstletter** , **Lastletter**  and also checking all the letters presence and count in features.\n",
    "> Selecting relevant features and deciding how to encode them are very important to build a  good model. \n",
    "\n",
    "In this model each letter of the word is evaluated against 'abcdefghijklmnopqrstuvwxyz' and each occurance is counted as part of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features_az(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'firstletter': 'j', 'lastletter': 'n', 'count(a)': 0, 'has(a)': False, 'count(b)': 0, 'has(b)': False, 'count(c)': 0, 'has(c)': False, 'count(d)': 0, 'has(d)': False, 'count(e)': 0, 'has(e)': False, 'count(f)': 0, 'has(f)': False, 'count(g)': 0, 'has(g)': False, 'count(h)': 1, 'has(h)': True, 'count(i)': 0, 'has(i)': False, 'count(j)': 1, 'has(j)': True, 'count(k)': 0, 'has(k)': False, 'count(l)': 0, 'has(l)': False, 'count(m)': 0, 'has(m)': False, 'count(n)': 1, 'has(n)': True, 'count(o)': 1, 'has(o)': True, 'count(p)': 0, 'has(p)': False, 'count(q)': 0, 'has(q)': False, 'count(r)': 0, 'has(r)': False, 'count(s)': 0, 'has(s)': False, 'count(t)': 0, 'has(t)': False, 'count(u)': 0, 'has(u)': False, 'count(v)': 0, 'has(v)': False, 'count(w)': 0, 'has(w)': False, 'count(x)': 0, 'has(x)': False, 'count(y)': 0, 'has(y)': False, 'count(z)': 0, 'has(z)': False}\n"
     ]
    }
   ],
   "source": [
    "print(gender_features_az('John'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B 1. Train and Test with  *`Gender Features A to Z`* and *`Base Gender Features`* \n",
    "Accuracy of naive Bayes classifier using the feature extractor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Last Letter  [classifier_base] check :0.782\n",
      "Accuracy First and Last Letter [classifier_az] check :0.82\n"
     ]
    }
   ],
   "source": [
    "featuresets_az = [(gender_features_az(n), g) for (n,g) in Gender_names]\n",
    "train_set, test_set = featuresets_az[500:], featuresets_az[:500]\n",
    "classifier_az = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy_az= nltk.classify.accuracy(classifier_az, test_set)\n",
    "print (\"Accuracy with Last Letter  [classifier_base] check :{}\".format(accuracy_base))\n",
    "print (\"Accuracy First and Last Letter [classifier_az] check :{}\".format(accuracy_az))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'firstletter': 'a', 'lastletter': 'i', 'count(a)': 1, 'has(a)': True, 'count(b)': 0, 'has(b)': False, 'count(c)': 0, 'has(c)': False, 'count(d)': 1, 'has(d)': True, 'count(e)': 0, 'has(e)': False, 'count(f)': 0, 'has(f)': False, 'count(g)': 0, 'has(g)': False, 'count(h)': 0, 'has(h)': False, 'count(i)': 1, 'has(i)': True, 'count(j)': 0, 'has(j)': False, 'count(k)': 0, 'has(k)': False, 'count(l)': 0, 'has(l)': False, 'count(m)': 0, 'has(m)': False, 'count(n)': 0, 'has(n)': False, 'count(o)': 0, 'has(o)': False, 'count(p)': 0, 'has(p)': False, 'count(q)': 0, 'has(q)': False, 'count(r)': 0, 'has(r)': False, 'count(s)': 0, 'has(s)': False, 'count(t)': 0, 'has(t)': False, 'count(u)': 0, 'has(u)': False, 'count(v)': 0, 'has(v)': False, 'count(w)': 0, 'has(w)': False, 'count(x)': 0, 'has(x)': False, 'count(y)': 0, 'has(y)': False, 'count(z)': 0, 'has(z)': False}, 'female')\n"
     ]
    }
   ],
   "source": [
    "# Listing One feature for Ref.\n",
    "print(featuresets_az[1])\n",
    "# list(featuresets_az[1][0].values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B 2. Featureset to Dataframe\n",
    "\n",
    "Converting featuresets_az to dataframe, this will help us plot the frquency graph of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duo</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>am</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ai</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pn</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>by</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ww</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Duo  Gender\n",
       "0  am    male\n",
       "1  ai  female\n",
       "2  pn    male\n",
       "3  by    male\n",
       "4  ww  female"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gf_az = pd.DataFrame(featuresets_az, columns=['Letter','Gender'])\n",
    "df_gf_az['Duo'] = df_gf_az['Letter'].apply(lambda x: list(x.values())[0] + list(x.values())[1]) \n",
    "df_gf_az = df_gf_az[['Duo','Gender']]\n",
    "df_gf_az.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7944, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_gf_az.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above result shows that the accuracy of classifier to count letters is about 2% more\n",
    "than the accuracy of a classifier that only pays attention to the final letter of each name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "First, we select a development set, containing the corpus data for creating the model. This development set is then subdivided into the *training set* and the *dev-test* set.\n",
    "<br>\n",
    "<br>\n",
    "**devtest_names :** Unique records from 500 to 1500 Index  <br>\n",
    "**train_names :** Unique records from 1500+ Index <br>\n",
    "**test_names :** Unique records from 0 to 500 Index <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = Gender_names[1500:]\n",
    "devtest_names = Gender_names[500:1500]\n",
    "test_names = Gender_names[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have divided the corpus into appropriate datasets. Then we have built a model using the training\n",
    "set, and then run it on the dev-test set.\n",
    "\n",
    "#### Running Base Gender Classifier with Last Letter (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features_base(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features_base(n), g) for (n,g) in devtest_names]\n",
    "test_set = [(gender_features_base(n), g) for (n,g) in test_names]\n",
    "classifier_base = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print (nltk.classify.accuracy(classifier_base, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Gender Classifier with First and Last Letter(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features_az(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features_az(n), g) for (n,g) in devtest_names]\n",
    "test_set = [(gender_features_az(n), g) for (n,g) in test_names]\n",
    "classifier_az = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print (nltk.classify.accuracy(classifier_az, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dev-test set, we can generate a list of the errors that the classifier makes when\n",
    "predicting name's gender:<br>\n",
    "Lets use our 500 Devtest_name to check the predictions by using the `classifier_base`  with Feature method : `gender_features_base`. <br>\n",
    "\n",
    "Here we will store all the errors in the `errors` when Predicted value is not equal to the right gender as per the test data.\n",
    "\n",
    "##### Finding Errors on Devtest_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier_base.classify(gender_features_base(name))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag, guess, name) )\n",
    "\n",
    "errors = sorted(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1000 names, we have noted 263 errors. i.e. success of 73.7%\n"
     ]
    }
   ],
   "source": [
    "print(\"Out of {} names, we have noted {} errors. i.e. success of {}%\".\n",
    "      format(len(devtest_names),\n",
    "             len(errors),\n",
    "             100-(len(errors)*100)/len(devtest_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names classifier that we have built generates about **229 errors** on the **devtest_names** corpus as follows, we are listing few of them as below : <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Abagail                       \n",
      "correct=female   guess=male     name=Aimil                         \n",
      "correct=female   guess=male     name=Alison                        \n",
      "correct=female   guess=male     name=Alys                          \n",
      "correct=female   guess=male     name=Amber                         \n",
      "correct=female   guess=male     name=Anais                         \n",
      "correct=female   guess=male     name=Annabell                      \n",
      "correct=female   guess=male     name=Anne-Mar                      \n",
      "correct=female   guess=male     name=Arden                         \n",
      "correct=female   guess=male     name=Beatriz                       \n"
     ]
    }
   ],
   "source": [
    "for (tag, guess, name) in errors[0:10]: # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n",
    "    print ('correct=%-8s guess=%-8s name=%-30s' % (tag, guess, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding Most Informative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     35.9 : 1.0\n",
      "             last_letter = 'k'              male : female =     34.7 : 1.0\n",
      "             last_letter = 'f'              male : female =     23.0 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.8 : 1.0\n",
      "             last_letter = 'd'              male : female =     11.2 : 1.0\n",
      "             last_letter = 'v'              male : female =      9.8 : 1.0\n",
      "             last_letter = 'm'              male : female =      8.9 : 1.0\n",
      "             last_letter = 'w'              male : female =      8.4 : 1.0\n",
      "             last_letter = 'o'              male : female =      7.8 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier_base.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noted that if last letter is `l` is mostly classified as *Male* but, `el` can be classified as Female.\n",
    "<br>Similarly We note that `n` is  mostly classified as *Male* but, `nn/an` can be classified as Female.\n",
    "\n",
    "### C. Gender Features Last Two Letters(gender_features_tls) : \n",
    "\n",
    "We will try to capture these features in our new model and build another model where we would consider the last two letters of the word and then train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect last Two Letters from the Words \n",
    "def gender_features_tls(word):\n",
    "    return {'suffix1': word[-1:], 'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suffix1': 'n', 'suffix2': 'hn'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features_tls(\"John\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C 1. Train and Test with  *`gender_features_tls`* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with model [gender_features_tls]  0.766\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features_tls(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features_tls(n), g) for (n,g) in devtest_names]\n",
    "classifier_tls = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print (\"Accuracy with model [gender_features_tls] \",nltk.classify.accuracy(classifier_tls, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuilding the classifier with the new feature extractor, we see that the performance\n",
    "on the dev-test dataset improves by almost one percentage points from 77.1% to 78.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Special Feature\n",
    "\n",
    "+ **gender_features_spl**\n",
    "\n",
    "We have created another features here which utilizes the first and last letter. It also looks for the prefix and suffix, or first and last two or three letters, depending on the name's length of a name and looks for whether or not any of the consonant clusters are present.\n",
    "\n",
    "+ **gender_features_icv**\n",
    "\n",
    "We are identifying all the vowels count and vowels in the name along with 1st and last letter of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features with irst and last letter. It also looks for the prefix and suffix, or first and last two or three letters.\n",
    "def gender_features_spl(name):\n",
    "    features = {}\n",
    "    temp_name = name\n",
    "    cons_clusters = [\"bl\", \"br\", \"ch\", \"cl\", \"cr\", \"dr\", \"fl\", \"fr\", \n",
    "                     \"gl\", \"gr\", \"pl\", \"pr\", \"sc\", \"sh\", \"sk\", \"sl\", \n",
    "                     \"sm\", \"sn\", \"sp\", \"st\", \"sw\", \"th\", \"tr\", \"tw\", \n",
    "                     \"wh\", \"wr\", \"sch\", \"scr\", \"shr\", \"sph\", \"spl\", \n",
    "                     \"spr\", \"squ\", \"str\", \"thr\"]\n",
    "    features[\"firstletter\"] = name[0].lower() \n",
    "    features[\"lastletter\"] = name[-1].lower() \n",
    "    features[\"prefix\"] = name[:3].lower() if len(name) > 4 else name[:2].lower() \n",
    "    features[\"suffix\"] = name[-3:].lower() if len(name) > 4 else name[-2:].lower()\n",
    "    clusters = []\n",
    "    for cluster in cons_clusters[::-1]:\n",
    "        if cluster in temp_name:\n",
    "            temp_name = temp_name.replace(cluster, \"\")\n",
    "            clusters.append(cluster)\n",
    "    features[\"consonant_clusters_1\"] = clusters[0] if len(clusters) > 0 else None\n",
    "    features[\"consonant_clusters_2\"] = clusters[1] if len(clusters) > 1 else None\n",
    "    features[\"consonant_clusters_3\"] = clusters[2] if len(clusters) > 2 else None\n",
    "    return features\n",
    "\n",
    "### Feature with Vowels count\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "def gender_features_icv(name):\n",
    "    features = {}\n",
    "    temp_name = name.lower()\n",
    "    lenName = len(name)    \n",
    "#     features[\"name_len\"] = len(name)\n",
    "    features[\"firstletter\"] = name[0].lower() \n",
    "    features[\"lastletter\"] = name[-1].lower() \n",
    "    features[\"prefix\"] = name[:3].lower() if len(name) > 4 else name[:2].lower() \n",
    "    features[\"suffix\"] = name[-3:].lower() if len(name) > 4 else name[-2:].lower()\n",
    "    Vowel = ['a','e','i','o','u']\n",
    "    Vclusters = []\n",
    "    flag = False\n",
    "    for vb in Vowel[::-1]:\n",
    "        if vb in temp_name:\n",
    "            n_vowels= temp_name.count(vb) # COunt how many times you see Vowels            \n",
    "            temp_name = temp_name.replace(vb, \"\")\n",
    "            Vclusters.append(vb)\n",
    "            features[vb]=n_vowels\n",
    "#             features[\"Len_vowel\"] = features[\"Len_vowel\"] + n_vowels\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Features test with class_gender_features4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstletter': 'a',\n",
       " 'lastletter': 'w',\n",
       " 'prefix': 'and',\n",
       " 'suffix': 'rew',\n",
       " 'consonant_clusters_1': 'dr',\n",
       " 'consonant_clusters_2': None,\n",
       " 'consonant_clusters_3': None}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features_spl(\"Andrew\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Features test with gender_features_icv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstletter': 'a',\n",
       " 'lastletter': 'w',\n",
       " 'prefix': 'and',\n",
       " 'suffix': 'rew',\n",
       " 'e': 1,\n",
       " 'a': 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features_icv(\"Andrew\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D 1. Train and Test with new Two news Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using feature **class_gender_features4** for extrating classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features_spl(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features_spl(n), g) for (n,g) in devtest_names]\n",
    "classifier_spl = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print (nltk.classify.accuracy(classifier_spl, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using feature **gender_features_icv** for extrating classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.817\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features_icv(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features_icv(n), g) for (n,g) in devtest_names]\n",
    "classifier_icv = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print (nltk.classify.accuracy(classifier_icv, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D 2. Check Informative Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "----------------------------Classifier classifier_spl----------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Most Informative Features\n",
      "              lastletter = 'a'            female : male   =     35.9 : 1.0\n",
      "              lastletter = 'k'              male : female =     34.7 : 1.0\n",
      "                  suffix = 'ard'            male : female =     25.7 : 1.0\n",
      "              lastletter = 'f'              male : female =     23.0 : 1.0\n",
      "                  suffix = 'tta'          female : male   =     22.6 : 1.0\n",
      "                  suffix = 'nne'          female : male   =     17.2 : 1.0\n",
      "                  suffix = 'vin'            male : female =     17.1 : 1.0\n",
      "                  suffix = 'na'           female : male   =     15.7 : 1.0\n",
      "                  suffix = 'old'            male : female =     15.0 : 1.0\n",
      "                  suffix = 'son'            male : female =     13.5 : 1.0\n",
      "                  prefix = 'ros'          female : male   =     12.7 : 1.0\n",
      "                  suffix = 'ene'          female : male   =     12.3 : 1.0\n",
      "              lastletter = 'p'              male : female =     11.8 : 1.0\n",
      "                  prefix = 'bri'          female : male   =     11.4 : 1.0\n",
      "                  suffix = 'ita'          female : male   =     11.2 : 1.0\n",
      "              lastletter = 'd'              male : female =     11.2 : 1.0\n",
      "                  prefix = 'tha'            male : female =     10.8 : 1.0\n",
      "                  suffix = 'ria'          female : male   =     10.5 : 1.0\n",
      "                  suffix = 'iah'            male : female =      9.8 : 1.0\n",
      "                  prefix = 'wa'             male : female =      9.8 : 1.0\n",
      "              lastletter = 'v'              male : female =      9.8 : 1.0\n",
      "                  prefix = 'jac'          female : male   =      9.7 : 1.0\n",
      "                  suffix = 'lle'          female : male   =      9.4 : 1.0\n",
      "                  suffix = 'lee'          female : male   =      9.4 : 1.0\n",
      "                  suffix = 'nni'          female : male   =      9.2 : 1.0\n",
      "None\n",
      "---------------------------------------------------------------------------------\n",
      "----------------------------Classifier classifier_icv----------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Most Informative Features\n",
      "              lastletter = 'a'            female : male   =     35.9 : 1.0\n",
      "              lastletter = 'k'              male : female =     34.7 : 1.0\n",
      "                  suffix = 'ard'            male : female =     25.7 : 1.0\n",
      "              lastletter = 'f'              male : female =     23.0 : 1.0\n",
      "                  suffix = 'tta'          female : male   =     22.6 : 1.0\n",
      "                  suffix = 'nne'          female : male   =     17.2 : 1.0\n",
      "                  suffix = 'vin'            male : female =     17.1 : 1.0\n",
      "                  suffix = 'na'           female : male   =     15.7 : 1.0\n",
      "                  suffix = 'old'            male : female =     15.0 : 1.0\n",
      "                  suffix = 'son'            male : female =     13.5 : 1.0\n",
      "                  prefix = 'ros'          female : male   =     12.7 : 1.0\n",
      "                  suffix = 'ene'          female : male   =     12.3 : 1.0\n",
      "              lastletter = 'p'              male : female =     11.8 : 1.0\n",
      "                  prefix = 'bri'          female : male   =     11.4 : 1.0\n",
      "                  suffix = 'ita'          female : male   =     11.2 : 1.0\n",
      "              lastletter = 'd'              male : female =     11.2 : 1.0\n",
      "                  prefix = 'tha'            male : female =     10.8 : 1.0\n",
      "                  suffix = 'ria'          female : male   =     10.5 : 1.0\n",
      "                  suffix = 'iah'            male : female =      9.8 : 1.0\n",
      "                  prefix = 'wa'             male : female =      9.8 : 1.0\n",
      "              lastletter = 'v'              male : female =      9.8 : 1.0\n",
      "                  prefix = 'jac'          female : male   =      9.7 : 1.0\n",
      "                  suffix = 'lle'          female : male   =      9.4 : 1.0\n",
      "                  suffix = 'lee'          female : male   =      9.4 : 1.0\n",
      "                  suffix = 'nni'          female : male   =      9.2 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------------------------------\")\n",
    "print(\"----------------------------Classifier classifier_spl----------------------------\")\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "print(classifier_spl.show_most_informative_features(25))\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "print(\"----------------------------Classifier classifier_icv----------------------------\")\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "print(classifier_icv.show_most_informative_features(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D 3. Check Erros on Devtest set\n",
    "\n",
    "* Erros from classifier_spl Model\n",
    "* Erros from classifier_icv Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With [classifier_spl] Out of 1000 names, we have noted 190 errors. i.e. success of 81.0%\n",
      "With [classifier_icv] Out of 1000 names, we have noted 183 errors. i.e. success of 81.7%\n"
     ]
    }
   ],
   "source": [
    "#--------------Errors with classifier_spl Model\n",
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier_spl.classify(gender_features_spl(name))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag, guess, name) )\n",
    "\n",
    "errors = sorted(errors)\n",
    "    \n",
    "print(\"With [classifier_spl] Out of {} names, we have noted {} errors. i.e. success of {}%\".\n",
    "      format(len(devtest_names),\n",
    "             len(errors),\n",
    "             100-(len(errors)*100)/len(devtest_names)))\n",
    "\n",
    "#-------------- Erros with classifier_icv Model\n",
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier_icv.classify(gender_features_icv(name))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag, guess, name) )\n",
    "\n",
    "errors = sorted(errors)\n",
    "\n",
    "print(\"With [classifier_icv] Out of {} names, we have noted {} errors. i.e. success of {}%\".\n",
    "      format(len(devtest_names),\n",
    "             len(errors),\n",
    "             100-(len(errors)*100)/len(devtest_names)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with All the Model\n",
    "\n",
    "We are using test size of 50% and then run all of the features on the train data to classifie and test it on the Test data, and also check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Accuracy with Last Letter  [classifier] check:                           0.7575528700906344\n",
      "2. Accuracy First and Last Letter [classifier_az] check :                   0.7726586102719033\n",
      "3. Accuracy Last Two Letter [classifier_tls] check:                         0.7787009063444109\n",
      "4. Accuracy First and Last Letter and last 2 letter [classifier_spl] check: 0.824773413897281\n",
      "5. Accuracy With All+ Vowels [classifier_icv] check:                        0.8250251762336355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split #split the test data to 50% of total data \n",
    "\n",
    "# Full Dataset copy in base_data\n",
    "base_data = [(n, g) for (n,g) in Gender_names]\n",
    "# split data into training and test data.\n",
    "gl_train_set, gl_test_set = train_test_split(base_data,train_size=0.5,test_size=0.5,shuffle =True)\n",
    "\n",
    "featuresets_train = [(gender_features_base(n), g) for (n,g) in gl_train_set]\n",
    "featuresets_test = [(gender_features_base(n), g) for (n,g) in gl_test_set]\n",
    "\n",
    "featuresets_az_train = [(gender_features_az(n), g) for (n,g) in gl_train_set]\n",
    "featuresets_az_test = [(gender_features_az(n), g) for (n,g) in gl_test_set]\n",
    "\n",
    "featuresets_tls_train = [(gender_features_tls(n), g) for (n,g) in gl_train_set]\n",
    "featuresets_tls_test = [(gender_features_tls(n), g) for (n,g) in gl_test_set]\n",
    "\n",
    "featuresets_spl_train = [(gender_features_spl(n), g) for (n,g) in gl_train_set]\n",
    "featuresets_spl_test = [(gender_features_spl(n), g) for (n,g) in gl_test_set]\n",
    "\n",
    "featuresets_icv_train = [(gender_features_icv(n), g) for (n,g) in gl_train_set]\n",
    "featuresets_icv_test = [(gender_features_icv(n), g) for (n,g) in gl_test_set]\n",
    "\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(featuresets_train)\n",
    "classifier_az = nltk.NaiveBayesClassifier.train(featuresets_az_train)\n",
    "classifier_spl = nltk.NaiveBayesClassifier.train(featuresets_spl_train)\n",
    "classifier_tls = nltk.NaiveBayesClassifier.train(featuresets_tls_train)\n",
    "classifier_icv = nltk.NaiveBayesClassifier.train(featuresets_icv_train)\n",
    "\n",
    "\n",
    "\n",
    "accuracy_base= nltk.classify.accuracy(classifier, featuresets_test)\n",
    "accuracy_az= nltk.classify.accuracy(classifier_az, featuresets_az_test)\n",
    "accuracy_spl= nltk.classify.accuracy(classifier_spl, featuresets_spl_test)\n",
    "accuracy_tls= nltk.classify.accuracy(classifier_tls, featuresets_tls_test)\n",
    "accuracy_icv= nltk.classify.accuracy(classifier_icv, featuresets_icv_test)\n",
    "\n",
    "print (\"1. Accuracy with Last Letter  [classifier] check:                           {}\".format(accuracy_base))\n",
    "print (\"2. Accuracy First and Last Letter [classifier_az] check :                   {}\".format(accuracy_az))\n",
    "print (\"3. Accuracy Last Two Letter [classifier_tls] check:                         {}\".format(accuracy_tls))\n",
    "print (\"4. Accuracy First and Last Letter and last 2 letter [classifier_spl] check: {}\".format(accuracy_spl))\n",
    "print (\"5. Accuracy With All+ Vowels [classifier_icv] check:                        {}\".format(accuracy_icv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy\n",
    "We will test the accuracy of of both gender features of finding the gender by last name and counting the letters of names here. To do this, we will run each function 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP STOP STOP STOP STOP STOP STOP STOP STOP STOP STOP STOP STOP STOP STOP STOP STOP STOP STOP STOP STOP \n",
    "EXECUTION EXECUTION  EXECUTION  EXECUTION  EXECUTION  EXECUTION  EXECUTION  EXECUTION  EXECUTION  EXECUTION \n",
    "Add on purpose so that we don't run the below code again which would change the conclusion ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function take number of Runs and Feature Extractor as input.\n",
    "def accuracy(number_of_runs, function_to_use):\n",
    "    acc_df = {\n",
    "        \"classifier\": [],\n",
    "        \"train_set_accuracy\": [],\n",
    "        \"test_set_accuracy\": [],\n",
    "        \"devtest_set_accuracy\": [],\n",
    "        \"devtest_errors\": []\n",
    "    }\n",
    "    for i in range(number_of_runs):\n",
    "        random.shuffle(Gender_names)\n",
    "        acc_train_names = Gender_names[1000:]\n",
    "        acc_devtest_names = Gender_names[500:1000]\n",
    "        acc_test_names = Gender_names[:500]\n",
    "        acc_train_set = [(function_to_use(n), g) for (n,g) in acc_train_names]\n",
    "        acc_devtest_set = [(function_to_use(n), g) for (n,g) in acc_devtest_names]\n",
    "        acc_test_set = [(function_to_use(n), g) for (n,g) in acc_test_names]\n",
    "        acc_classifier = nltk.NaiveBayesClassifier.train(acc_train_set)\n",
    "        acc_df[\"classifier\"].append(acc_classifier)\n",
    "        acc_df[\"train_set_accuracy\"].append(nltk.classify.accuracy(acc_classifier, acc_train_set))\n",
    "        acc_df[\"test_set_accuracy\"].append(nltk.classify.accuracy(acc_classifier, acc_test_set))\n",
    "        acc_df[\"devtest_set_accuracy\"].append(nltk.classify.accuracy(acc_classifier, acc_devtest_set))\n",
    "        acc_errors = []\n",
    "        for (name, tag) in acc_devtest_names:\n",
    "            acc_guess = acc_classifier.classify(function_to_use(name))\n",
    "            if acc_guess != tag:\n",
    "                acc_errors.append( (tag, acc_guess, name) )\n",
    "        acc_df[\"devtest_errors\"].append(acc_errors)\n",
    "    acc_df = pd.DataFrame.from_dict(acc_df)\n",
    "    return(acc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running accuracy test with Fifity runs and all the Classifier we have created so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_df_base = accuracy(50, gender_features_base)\n",
    "Accuracy_df_az = accuracy(50, gender_features_az)\n",
    "Accuracy_df_spl = accuracy(50, gender_features_spl)\n",
    "Accuracy_df_icv = accuracy(50, gender_features_icv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Results with Test data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_9d12d608_a133_11e9_bcf2_00ac36084ec3row0_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9d12d608_a133_11e9_bcf2_00ac36084ec3row1_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9d12d608_a133_11e9_bcf2_00ac36084ec3row2_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9d12d608_a133_11e9_bcf2_00ac36084ec3row3_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9d12d608_a133_11e9_bcf2_00ac36084ec3row4_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9d12d608_a133_11e9_bcf2_00ac36084ec3row5_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9d12d608_a133_11e9_bcf2_00ac36084ec3row6_col3 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Base Classifier</th>        <th class=\"col_heading level0 col1\" >AtoZ Classifier</th>        <th class=\"col_heading level0 col2\" >Classifier SPL</th>        <th class=\"col_heading level0 col3\" >Classifier ICV</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3level0_row0\" class=\"row_heading level0 row0\" >mean</th>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row0_col0\" class=\"data row0 col0\" >0.75932</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row0_col1\" class=\"data row0 col1\" >0.77132</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row0_col2\" class=\"data row0 col2\" >0.83448</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row0_col3\" class=\"data row0 col3\" >0.83184</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3level0_row1\" class=\"row_heading level0 row1\" >std</th>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row1_col0\" class=\"data row1 col0\" >0.0147447</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row1_col1\" class=\"data row1 col1\" >0.0182974</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row1_col2\" class=\"data row1 col2\" >0.0169058</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row1_col3\" class=\"data row1 col3\" >0.0179379</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3level0_row2\" class=\"row_heading level0 row2\" >min</th>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row2_col0\" class=\"data row2 col0\" >0.718</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row2_col1\" class=\"data row2 col1\" >0.738</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row2_col2\" class=\"data row2 col2\" >0.798</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row2_col3\" class=\"data row2 col3\" >0.786</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3level0_row3\" class=\"row_heading level0 row3\" >25%</th>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row3_col0\" class=\"data row3 col0\" >0.75</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row3_col1\" class=\"data row3 col1\" >0.758</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row3_col2\" class=\"data row3 col2\" >0.824</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row3_col3\" class=\"data row3 col3\" >0.822</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3level0_row4\" class=\"row_heading level0 row4\" >50%</th>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row4_col0\" class=\"data row4 col0\" >0.76</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row4_col1\" class=\"data row4 col1\" >0.771</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row4_col2\" class=\"data row4 col2\" >0.832</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row4_col3\" class=\"data row4 col3\" >0.831</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3level0_row5\" class=\"row_heading level0 row5\" >75%</th>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row5_col0\" class=\"data row5 col0\" >0.768</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row5_col1\" class=\"data row5 col1\" >0.784</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row5_col2\" class=\"data row5 col2\" >0.844</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row5_col3\" class=\"data row5 col3\" >0.842</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3level0_row6\" class=\"row_heading level0 row6\" >max</th>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row6_col0\" class=\"data row6 col0\" >0.798</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row6_col1\" class=\"data row6 col1\" >0.808</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row6_col2\" class=\"data row6 col2\" >0.872</td>\n",
       "                        <td id=\"T_9d12d608_a133_11e9_bcf2_00ac36084ec3row6_col3\" class=\"data row6 col3\" >0.88</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x25df9c95f28>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_acc = pd.concat([Accuracy_df_base.describe()['test_set_accuracy'], \n",
    "                  Accuracy_df_az.describe()['test_set_accuracy'],\n",
    "                  Accuracy_df_spl.describe()['test_set_accuracy'],\n",
    "                  Accuracy_df_icv.describe()['test_set_accuracy']], axis=1)\n",
    "print(\"Classifier Results with Test data\")\n",
    "df_test_acc.columns = ['Base Classifier', 'AtoZ Classifier','Classifier SPL','Classifier ICV']\n",
    "\n",
    "\n",
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "df_test_acc.iloc[1:].style.apply(highlight_max,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "The **Mean** of accuracy of the *test data* with the **Base Classifier** is ~76% where as with **Classifier SPL** it's 83.48%.\n",
    "We also noted that **Classifier SPL** is doing better in all the stats of the accuracy, also with **Classifer ICV** we noted **Maximum accuracy of 88%** in total 50 runs of the data.\n",
    "\n",
    "We tried many approaches:\n",
    "* Cosine distance of Vowels\n",
    "* Consonant Count = Total length - Length of Vowel\n",
    "* Cosine distance of 1st and 2nd letter, 2nd and 3rd letter, last and 2nd last letter.\n",
    "\n",
    "All the above approaches with new features,resulted in worst or no improvement in the overall accuracy with  **Classifier ICV**. By using a simple technique of identifying the vowels we were able to  achieve 8% extra accuracy from model **AtoZ Classifier**  with max accuracy of 80% to 88%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>*********************************************<br>\n",
    "***************<br>********<br></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
